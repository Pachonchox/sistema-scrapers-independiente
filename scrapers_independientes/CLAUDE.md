# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Descripci√≥n del Proyecto

**üöÄ Sistema de Scrapers Independiente V5** - Sistema completo de scraping aut√≥nomo para 6 retailers chilenos principales con soporte completo de emojis UTF-8 y arquitectura V5 optimizada. El sistema incluye orquestador inteligente, extracci√≥n de campos completos, anti-detecci√≥n avanzada y exportaci√≥n automatizada.

## Comandos de Desarrollo

### üöÄ Instalaci√≥n y Configuraci√≥n

```bash
# Instalaci√≥n autom√°tica completa
python setup.py

# Instalaci√≥n manual de dependencias
pip install -r requirements.txt
python -m playwright install chromium

# Configuraci√≥n de directorios
mkdir resultados
mkdir logs
```

### üéØ Ejecuci√≥n Principal (Orquestador V5)

```bash
# Ejecutar todos los scrapers (modo concurrente)
python orchestrator.py --mode concurrent --max-products 200

# Ejecutar scraper espec√≠fico
python orchestrator.py --retailer paris --max-products 100
python orchestrator.py --retailer falabella --max-products 150

# M√∫ltiples retailers espec√≠ficos
python orchestrator.py --retailers paris falabella ripley --mode sequential

# Modo test (r√°pido para validaci√≥n)
python orchestrator.py --mode test

# Modo secuencial (m√°s estable)
python orchestrator.py --mode sequential --max-products 100
```

### üéõÔ∏è Sistema Alternativo

```bash
# Ejecutar todos los retailers
python run_complete_system.py --all-retailers --max-products 100

# Retailer espec√≠fico
python run_complete_system.py --retailer hites --max-products 150

# Sistema legacy
python run_scrapers_system.py
python run_scrapers_system.py falabella

# Windows (un click)
EJECUTAR_SCRAPERS.bat
```

### üß™ Testing y Validaci√≥n

```bash
# Test completo del sistema
python test_system.py

# Test scraper individual  
python run_scrapers_system.py falabella

# Validaci√≥n de configuraci√≥n
python -c "import json; print('‚úÖ Config OK' if json.load(open('config.json')) else '‚ùå Config Error')"
```

## Arquitectura del Sistema

### üèóÔ∏è Componentes Principales

El sistema est√° organizado en m√∫ltiples capas de abstracci√≥n:

**1. Orquestadores (Puntos de Entrada)**
- `orchestrator.py` - ‚≠ê **Orquestador Principal V5** (recomendado) - Ejecuci√≥n concurrente, secuencial o test
- `run_complete_system.py` - Sistema alternativo con extracci√≥n de campos completos
- `run_scrapers_system.py` - Sistema legacy para compatibilidad

**2. Core Architecture (`core/`)**
- `base_scraper.py` - Clase base V5 con integraci√≥n ML completa, anti-detecci√≥n y auto-recovery
- `utils.py` - Utilidades compartidas para exportaci√≥n, logging y formateo
- `orchestrator.py` - Orquestador interno del core
- `anti_detection_system.py` - Sistema anti-detecci√≥n avanzado
- `emoji_support.py` - Soporte completo UTF-8 y emojis multiplataforma
- `field_mapper.py` - Mapeo y transformaci√≥n de campos de datos
- `intelligent_scheduler.py` - Scheduler inteligente con ML
- `advanced_tier_manager.py` - Gesti√≥n avanzada de niveles y prioridades
- `exceptions.py` - Excepciones personalizadas del sistema

**3. Scrapers Espec√≠ficos (`scrapers/`)**
- `paris_scraper_v5_improved.py` - 15+ campos completos
- `paris_scraper_v5_port_integrated.py` - Versi√≥n integrada con campos PORT
- `ripley_scraper_v5_improved.py` - 18+ campos completos  
- `falabella_scraper_v5_improved.py` - 14+ campos completos
- `falabella_scraper_v5_parallel.py` - Versi√≥n paralela optimizada
- `hites_scraper_v5_improved.py` - 16+ campos completos
- `abcdin_scraper_v5_improved.py` - 17+ campos completos

### üß† Arquitectura de Scrapers

Todos los scrapers heredan de `BaseScraperV5` que proporciona:

- **Anti-detecci√≥n inteligente**: Rotaci√≥n de User Agents, delays aleatorios, headers realistas
- **Manejo robusto de errores**: Reintentos autom√°ticos, circuit breakers, fallbacks
- **Extracci√≥n de campos completos**: Selectores optimizados para maximizar datos extra√≠dos
- **Soporte emoji nativo**: Logging visual con emojis UTF-8
- **Configuraci√≥n por retailer**: Timeouts, selectores y comportamiento espec√≠fico

### üéØ Modos de Ejecuci√≥n

| Modo | Archivo | Descripci√≥n | Uso Recomendado |
|------|---------|-------------|-----------------|
| **concurrent** | `orchestrator.py` | M√∫ltiples scrapers en paralelo | M√°ximo rendimiento |
| **sequential** | `orchestrator.py` | Scrapers uno tras otro | M√°xima estabilidad |
| **test** | `orchestrator.py` | Pocos productos, validaci√≥n r√°pida | Testing y desarrollo |
| **individual** | `orchestrator.py --retailer X` | Un scraper espec√≠fico | Debugging espec√≠fico |

### üìä Sistema de Exportaci√≥n

**Archivos Generados:**
- **Excel individuales**: `retailer_complete_YYYYMMDD_HHMMSS.xlsx` con 14-18 campos por retailer
- **Excel consolidado**: `TODOS_RETAILERS_YYYYMMDD_HHMMSS.xlsx` con datos unificados
- **JSON detallado**: `orchestrator_results_YYYYMMDD_HHMMSS.json` con metadatos y estad√≠sticas
- **Logs con emojis**: `orchestrator.log` y `scrapers_system.log` con seguimiento visual

## Configuraci√≥n del Sistema

### üîß Archivo Principal (`config.json`)

```json
{
  "sistema": {
    "emoji_support": true,        // Soporte emojis forzado
    "max_workers": 1,             // 1=secuencial, >1=paralelo  
    "export_excel": true,         // Exportar Excel individuales
    "export_unified": true        // Crear reporte unificado
  },
  "anti_deteccion": {
    "user_agents": [...],         // 4+ navegadores reales
    "delay_min": 1,               // Delay m√≠nimo entre requests
    "delay_max": 3,               // Delay m√°ximo entre requests
    "max_reintentos": 3,          // Reintentos autom√°ticos
    "headless": true              // Navegador invisible
  },
  "retailers": {
    "falabella": {
      "activo": true,             // Activar/desactivar retailer
      "max_productos": 20,        // L√≠mite productos por ejecuci√≥n
      "selectores": {...},        // Selectores CSS espec√≠ficos
      "browser_config": {...}     // Configuraci√≥n navegador espec√≠fica
    }
  }
}
```

### ‚öôÔ∏è Configuraciones Espec√≠ficas por Retailer

- **Ripley**: Navegador visible off-screen (-2000, 0) + scroll obligatorio para carga din√°mica
- **AbcDin**: Wait for DOM content loaded antes de extraer datos
- **Todos**: Timeouts personalizados y configuraci√≥n espec√≠fica de selectores

## Caracter√≠sticas Anti-Detecci√≥n

### üõ°Ô∏è Implementaciones V5

- **Rotaci√≥n User Agents**: 4+ navegadores reales (Chrome, Firefox, Safari) con versiones actualizadas
- **Delays Inteligentes**: Aleatorios entre 1-3s configurables por retailer
- **Headers Completos**: Accept, Language, Encoding, Referer realistas
- **Webdriver Ocultado**: Properties de automation eliminadas completamente
- **Viewport Realista**: 1920x1080 como configuraci√≥n est√°ndar
- **Configuraci√≥n Espec√≠fica**: Por retailer con timeouts y comportamientos √∫nicos

### üéØ Sistemas Especiales

- **Ripley**: Navegador visible en posici√≥n off-screen con scroll autom√°tico
- **AbcDin**: Espera DOM content loaded para evitar timeouts
- **Todos**: Sistema de reintentos con backoff exponencial

## Desarrollo y Mantenimiento

### üìù Gu√≠as de Desarrollo

**Est√°ndares de C√≥digo:**
- **Soporte Emojis Obligatorio**: Todos los scripts deben soportar UTF-8 y emojis üòä
- **Logging con Emojis**: Usar emojis contextuales para identificaci√≥n visual r√°pida
- **Error Handling Robusto**: try-catch con mensajes descriptivos y emojis de estado
- **Async/Await Preferido**: Para operaciones I/O intensivas
- **Type Hints**: Incluir anotaciones de tipo para mejor claridad
- **Documentaci√≥n Inline**: Docstrings completos con descripci√≥n, par√°metros y retorno

### üîß Actualizaci√≥n de Selectores

Si un scraper deja de funcionar:

1. **Inspeccionar la p√°gina manualmente** (F12 en navegador)
2. **Actualizar selectores en `config.json`** o archivos de scraper espec√≠ficos
3. **Probar con modo test**: `python orchestrator.py --mode test`
4. **Validar extracci√≥n completa**: Verificar que todos los campos esperados se extraen

### üß™ Testing del Sistema

```bash
# Validaci√≥n completa del sistema
python test_system.py

# Test r√°pido del orquestador (modo test - 10 productos)
python orchestrator.py --mode test

# Test scraper individual con pocos productos
python orchestrator.py --retailer paris --max-products 10

# Test de retailers espec√≠ficos disponibles
python orchestrator.py --retailers paris falabella abcdin --mode sequential --max-products 20

# Verificar scrapers disponibles desde el c√≥digo
python -c "from orchestrator import SCRAPERS_MAPPING; print('üï∑Ô∏è Scrapers disponibles:', list(SCRAPERS_MAPPING.keys()))"

# Verificar emojis y UTF-8
python -c "print('‚úÖ üöÄ üòä üí∞ üìä Emojis funcionando correctamente')"

# Test espec√≠fico para debugging
python debug_extraction_flow.py
python debug_paris_selectors.py
```

### üìä M√©tricas y Monitoreo

**M√©tricas Incluidas:**
- **Productos por segundo**: Eficiencia de extracci√≥n
- **Campos extra√≠dos vs esperados**: Porcentaje de completitud de datos
- **Tiempo por retailer**: Performance individual
- **Tasa de √©xito**: Scrapers exitosos vs fallidos
- **Calidad de datos**: Validaci√≥n de campos obligatorios

### üîÑ Resoluci√≥n de Problemas Comunes

**Python no encontrado:**
```bash
# Descargar desde python.org, asegurar "Add to PATH"
python --version  # Verificar instalaci√≥n
```

**Playwright/navegadores faltantes:**
```bash
pip install playwright
python -m playwright install chromium
```

**Emojis no se muestran correctamente:**
- Terminal: Verificar soporte UTF-8
- Windows: Usar Windows Terminal o configurar codepage UTF-8
- Logs: Los archivos siempre guardan correctamente en UTF-8

**Sin productos extra√≠dos:**
- Verificar conexi√≥n internet
- Reducir `max_productos` para testing
- Revisar logs detallados en `resultados/`
- Actualizar selectores si la p√°gina web cambi√≥

### üåü Optimizaci√≥n de Performance

**Para M√°ximo Rendimiento:**
```json
{
  "max_workers": 3,
  "delay_min": 1,
  "delay_max": 2,
  "headless": true
}
```

**Para M√°xima Estabilidad:**
```json
{
  "max_workers": 1,
  "delay_min": 3,
  "delay_max": 6,
  "headless": true
}
```

## Estructura de Archivos Clave

```
scrapers_independientes/
‚îú‚îÄ‚îÄ orchestrator.py              # üöÄ ORQUESTADOR PRINCIPAL V5
‚îú‚îÄ‚îÄ run_complete_system.py       # Sistema alternativo
‚îú‚îÄ‚îÄ run_scrapers_system.py       # Sistema legacy
‚îú‚îÄ‚îÄ config.json                  # Configuraci√≥n centralizada
‚îú‚îÄ‚îÄ setup.py                     # Instalador autom√°tico
‚îú‚îÄ‚îÄ EJECUTAR_SCRAPERS.bat       # Script Windows
‚îú‚îÄ‚îÄ core/                        # Motor V5
‚îÇ   ‚îú‚îÄ‚îÄ base_scraper.py         # Clase base con ML
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                # Utilidades compartidas
‚îÇ   ‚îú‚îÄ‚îÄ anti_detection_system.py # Anti-detecci√≥n avanzado
‚îÇ   ‚îî‚îÄ‚îÄ emoji_support.py        # Soporte UTF-8 completo
‚îú‚îÄ‚îÄ scrapers/                    # Scrapers espec√≠ficos V5
‚îÇ   ‚îú‚îÄ‚îÄ paris_scraper_v5_improved.py    # 15+ campos
‚îÇ   ‚îú‚îÄ‚îÄ paris_scraper_v5_port_integrated.py # Integraci√≥n PORT
‚îÇ   ‚îú‚îÄ‚îÄ ripley_scraper_v5_improved.py   # 18+ campos
‚îÇ   ‚îú‚îÄ‚îÄ falabella_scraper_v5_improved.py # 14+ campos
‚îÇ   ‚îú‚îÄ‚îÄ falabella_scraper_v5_parallel.py # Versi√≥n paralela
‚îÇ   ‚îú‚îÄ‚îÄ hites_scraper_v5_improved.py    # 16+ campos
‚îÇ   ‚îî‚îÄ‚îÄ abcdin_scraper_v5_improved.py   # 17+ campos
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ retailers.json           # Configuraci√≥n detallada
‚îî‚îÄ‚îÄ resultados/                  # Archivos generados
    ‚îú‚îÄ‚îÄ *.xlsx                   # Excel con campos completos
    ‚îú‚îÄ‚îÄ *.json                   # Datos + metadatos
    ‚îî‚îÄ‚îÄ *.log                    # Logs con emojis
```

## Notas Importantes

- **üéØ Punto de Entrada Recomendado**: `orchestrator.py` con modo concurrent para mejor performance
- **üòä Emojis Obligatorios**: Todos los scripts fuerzan soporte UTF-8 y emojis nativos
- **üõ°Ô∏è Anti-detecci√≥n Activa**: Sistema robusto con rotaciones y delays inteligentes
- **üìä Datos Completos**: 14-18 campos por retailer vs 5-8 b√°sicos de sistemas anteriores
- **üîß Mantenimiento Simple**: Sistema autocontenido sin dependencias externas complejas
- **‚ö° Performance Optimizada**: Modos concurrent/sequential para diferentes necesidades

El sistema est√° dise√±ado para ser completamente aut√≥nomo y funcional desde la primera ejecuci√≥n, con capacidades avanzadas de extracci√≥n de datos y soporte completo de emojis para mejor experiencia visual.

## Estado Actual de los Scrapers

### üü¢ Scrapers Activos y Funcionales
Seg√∫n el archivo `orchestrator.py`, los scrapers actualmente disponibles son:

- **Paris**: `paris_scraper_v5_port_integrated.py` (integrado con campos PORT)
- **Falabella**: `falabella_scraper_v5_parallel.py` (versi√≥n paralela optimizada)  
- **AbcDin**: `abcdin_scraper_v5_improved.py` (campos completos)

### üü° Scrapers en Desarrollo/Desactivados
- **Ripley**: Comentado temporalmente en orchestrator.py
- **Hites**: Comentado temporalmente en orchestrator.py

### üìä Configuraci√≥n de Retailers en config.json

Seg√∫n la configuraci√≥n actual:
- **Falabella**: ‚úÖ Activo
- **Paris**: ‚úÖ Activo  
- **Ripley**: ‚úÖ Activo (configurado pero con navegador visible off-screen)
- **Hites**: ‚ùå Desactivado (`"activo": false`)
- **AbcDin**: ‚ùå Desactivado (`"activo": false`)
- **MercadoLibre**: ‚úÖ Activo

**Nota**: Existe una discrepancia entre la configuraci√≥n JSON y los scrapers importados en el orquestador. Para activar todos los scrapers, es necesario:
1. Activar los retailers desactivados en `config.json`
2. Descomentar las importaciones en `orchestrator.py`
3. Verificar que todos los archivos de scraper existan y funcionen correctamente