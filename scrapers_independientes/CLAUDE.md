# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## DescripciÃ³n del Proyecto

**ğŸš€ Sistema de Scrapers Independiente V5** - Sistema completo de scraping autÃ³nomo para 6 retailers chilenos principales con soporte completo de emojis UTF-8 y arquitectura V5 optimizada. El sistema incluye orquestador inteligente, extracciÃ³n de campos completos, anti-detecciÃ³n avanzada y exportaciÃ³n automatizada.

## Comandos de Desarrollo

### ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

```bash
# InstalaciÃ³n automÃ¡tica completa
python setup.py

# InstalaciÃ³n manual de dependencias
pip install -r requirements.txt
python -m playwright install chromium

# ConfiguraciÃ³n de directorios
mkdir resultados
mkdir logs
```

### ğŸ¯ EjecuciÃ³n Principal (Orquestador V5)

```bash
# Ejecutar todos los scrapers (modo concurrente)
python orchestrator.py --mode concurrent --max-products 200

# Ejecutar scraper especÃ­fico
python orchestrator.py --retailer paris --max-products 100
python orchestrator.py --retailer falabella --max-products 150

# MÃºltiples retailers especÃ­ficos
python orchestrator.py --retailers paris falabella ripley --mode sequential

# Modo test (rÃ¡pido para validaciÃ³n)
python orchestrator.py --mode test

# Modo secuencial (mÃ¡s estable)
python orchestrator.py --mode sequential --max-products 100
```

### ğŸ›ï¸ Sistema Alternativo

```bash
# Ejecutar todos los retailers
python run_complete_system.py --all-retailers --max-products 100

# Retailer especÃ­fico
python run_complete_system.py --retailer hites --max-products 150

# Sistema legacy
python run_scrapers_system.py
python run_scrapers_system.py falabella

# Windows (un click)
EJECUTAR_SCRAPERS.bat
```

### ğŸ§ª Testing y ValidaciÃ³n

```bash
# Test completo del sistema
python test_system.py

# Test scraper individual  
python run_scrapers_system.py falabella

# ValidaciÃ³n de configuraciÃ³n
python -c "import json; print('âœ… Config OK' if json.load(open('config.json')) else 'âŒ Config Error')"
```

## Arquitectura del Sistema

### ğŸ—ï¸ Componentes Principales

El sistema estÃ¡ organizado en mÃºltiples capas de abstracciÃ³n:

**1. Orquestadores (Puntos de Entrada)**
- `orchestrator.py` - â­ **Orquestador Principal V5** (recomendado) - EjecuciÃ³n concurrente, secuencial o test
- `run_complete_system.py` - Sistema alternativo con extracciÃ³n de campos completos
- `run_scrapers_system.py` - Sistema legacy para compatibilidad

**2. Core Architecture (`core/`)**
- `base_scraper.py` - Clase base V5 con integraciÃ³n ML completa, anti-detecciÃ³n y auto-recovery
- `utils.py` - Utilidades compartidas para exportaciÃ³n, logging y formateo
- `orchestrator.py` - Orquestador interno del core
- `anti_detection_system.py` - Sistema anti-detecciÃ³n avanzado
- `emoji_support.py` - Soporte completo UTF-8 y emojis multiplataforma
- `field_mapper.py` - Mapeo y transformaciÃ³n de campos de datos
- `intelligent_scheduler.py` - Scheduler inteligente con ML
- `advanced_tier_manager.py` - GestiÃ³n avanzada de niveles y prioridades
- `exceptions.py` - Excepciones personalizadas del sistema

**3. Scrapers EspecÃ­ficos (`scrapers/`)**
- `paris_scraper_v5_improved.py` - 15+ campos completos
- `paris_scraper_v5_port_integrated.py` - VersiÃ³n integrada con campos PORT
- `ripley_scraper_v5_improved.py` - 18+ campos completos  
- `falabella_scraper_v5_improved.py` - 14+ campos completos
- `falabella_scraper_v5_parallel.py` - VersiÃ³n paralela optimizada
- `hites_scraper_v5_improved.py` - 16+ campos completos
- `abcdin_scraper_v5_improved.py` - 17+ campos completos

### ğŸ§  Arquitectura de Scrapers

Todos los scrapers heredan de `BaseScraperV5` que proporciona:

- **Anti-detecciÃ³n inteligente**: RotaciÃ³n de User Agents, delays aleatorios, headers realistas
- **Manejo robusto de errores**: Reintentos automÃ¡ticos, circuit breakers, fallbacks
- **ExtracciÃ³n de campos completos**: Selectores optimizados para maximizar datos extraÃ­dos
- **Soporte emoji nativo**: Logging visual con emojis UTF-8
- **ConfiguraciÃ³n por retailer**: Timeouts, selectores y comportamiento especÃ­fico

### ğŸ¯ Modos de EjecuciÃ³n

| Modo | Archivo | DescripciÃ³n | Uso Recomendado |
|------|---------|-------------|-----------------|
| **concurrent** | `orchestrator.py` | MÃºltiples scrapers en paralelo | MÃ¡ximo rendimiento |
| **sequential** | `orchestrator.py` | Scrapers uno tras otro | MÃ¡xima estabilidad |
| **test** | `orchestrator.py` | Pocos productos, validaciÃ³n rÃ¡pida | Testing y desarrollo |
| **individual** | `orchestrator.py --retailer X` | Un scraper especÃ­fico | Debugging especÃ­fico |

### ğŸ“Š Sistema de ExportaciÃ³n

**Archivos Generados:**
- **Excel individuales**: `retailer_complete_YYYYMMDD_HHMMSS.xlsx` con 14-18 campos por retailer
- **Excel consolidado**: `TODOS_RETAILERS_YYYYMMDD_HHMMSS.xlsx` con datos unificados
- **JSON detallado**: `orchestrator_results_YYYYMMDD_HHMMSS.json` con metadatos y estadÃ­sticas
- **Logs con emojis**: `orchestrator.log` y `scrapers_system.log` con seguimiento visual

## ConfiguraciÃ³n del Sistema

### ğŸ”§ Archivo Principal (`config.json`)

```json
{
  "sistema": {
    "emoji_support": true,        // Soporte emojis forzado
    "max_workers": 1,             // 1=secuencial, >1=paralelo  
    "export_excel": true,         // Exportar Excel individuales
    "export_unified": true        // Crear reporte unificado
  },
  "anti_deteccion": {
    "user_agents": [...],         // 4+ navegadores reales
    "delay_min": 1,               // Delay mÃ­nimo entre requests
    "delay_max": 3,               // Delay mÃ¡ximo entre requests
    "max_reintentos": 3,          // Reintentos automÃ¡ticos
    "headless": true              // Navegador invisible
  },
  "retailers": {
    "falabella": {
      "activo": true,             // Activar/desactivar retailer
      "max_productos": 20,        // LÃ­mite productos por ejecuciÃ³n
      "selectores": {...},        // Selectores CSS especÃ­ficos
      "browser_config": {...}     // ConfiguraciÃ³n navegador especÃ­fica
    }
  }
}
```

### âš™ï¸ Configuraciones EspecÃ­ficas por Retailer

- **Ripley**: Navegador visible off-screen (-2000, 0) + scroll obligatorio para carga dinÃ¡mica
- **AbcDin**: Wait for DOM content loaded antes de extraer datos
- **Todos**: Timeouts personalizados y configuraciÃ³n especÃ­fica de selectores

## CaracterÃ­sticas Anti-DetecciÃ³n

### ğŸ›¡ï¸ Implementaciones V5

- **RotaciÃ³n User Agents**: 4+ navegadores reales (Chrome, Firefox, Safari) con versiones actualizadas
- **Delays Inteligentes**: Aleatorios entre 1-3s configurables por retailer
- **Headers Completos**: Accept, Language, Encoding, Referer realistas
- **Webdriver Ocultado**: Properties de automation eliminadas completamente
- **Viewport Realista**: 1920x1080 como configuraciÃ³n estÃ¡ndar
- **ConfiguraciÃ³n EspecÃ­fica**: Por retailer con timeouts y comportamientos Ãºnicos

### ğŸ¯ Sistemas Especiales

- **Ripley**: Navegador visible en posiciÃ³n off-screen con scroll automÃ¡tico
- **AbcDin**: Espera DOM content loaded para evitar timeouts
- **Todos**: Sistema de reintentos con backoff exponencial

## Desarrollo y Mantenimiento

### ğŸ“ GuÃ­as de Desarrollo

**EstÃ¡ndares de CÃ³digo:**
- **Soporte Emojis Obligatorio**: Todos los scripts deben soportar UTF-8 y emojis ğŸ˜Š
- **Logging con Emojis**: Usar emojis contextuales para identificaciÃ³n visual rÃ¡pida
- **Error Handling Robusto**: try-catch con mensajes descriptivos y emojis de estado
- **Async/Await Preferido**: Para operaciones I/O intensivas
- **Type Hints**: Incluir anotaciones de tipo para mejor claridad
- **DocumentaciÃ³n Inline**: Docstrings completos con descripciÃ³n, parÃ¡metros y retorno

### ğŸ”§ ActualizaciÃ³n de Selectores

Si un scraper deja de funcionar:

1. **Inspeccionar la pÃ¡gina manualmente** (F12 en navegador)
2. **Actualizar selectores en `config.json`** o archivos de scraper especÃ­ficos
3. **Probar con modo test**: `python orchestrator.py --mode test`
4. **Validar extracciÃ³n completa**: Verificar que todos los campos esperados se extraen

### ğŸ§ª Testing del Sistema

```bash
# ValidaciÃ³n completa del sistema
python test_system.py

# Test rÃ¡pido del orquestador (modo test - 10 productos)
python orchestrator.py --mode test

# Test scraper individual con pocos productos
python orchestrator.py --retailer paris --max-products 10

# Test de retailers especÃ­ficos disponibles
python orchestrator.py --retailers paris falabella abcdin --mode sequential --max-products 20

# Verificar scrapers disponibles desde el cÃ³digo
python -c "from orchestrator import SCRAPERS_MAPPING; print('ğŸ•·ï¸ Scrapers disponibles:', list(SCRAPERS_MAPPING.keys()))"

# Verificar emojis y UTF-8
python -c "print('âœ… ğŸš€ ğŸ˜Š ğŸ’° ğŸ“Š Emojis funcionando correctamente')"

# Test especÃ­fico para debugging
python debug_extraction_flow.py
python debug_paris_selectors.py
```

### ğŸ“Š MÃ©tricas y Monitoreo

**MÃ©tricas Incluidas:**
- **Productos por segundo**: Eficiencia de extracciÃ³n
- **Campos extraÃ­dos vs esperados**: Porcentaje de completitud de datos
- **Tiempo por retailer**: Performance individual
- **Tasa de Ã©xito**: Scrapers exitosos vs fallidos
- **Calidad de datos**: ValidaciÃ³n de campos obligatorios

### ğŸ”„ ResoluciÃ³n de Problemas Comunes

**Python no encontrado:**
```bash
# Descargar desde python.org, asegurar "Add to PATH"
python --version  # Verificar instalaciÃ³n
```

**Playwright/navegadores faltantes:**
```bash
pip install playwright
python -m playwright install chromium
```

**Emojis no se muestran correctamente:**
- Terminal: Verificar soporte UTF-8
- Windows: Usar Windows Terminal o configurar codepage UTF-8
- Logs: Los archivos siempre guardan correctamente en UTF-8

**Sin productos extraÃ­dos:**
- Verificar conexiÃ³n internet
- Reducir `max_productos` para testing
- Revisar logs detallados en `resultados/`
- Actualizar selectores si la pÃ¡gina web cambiÃ³

### ğŸŒŸ OptimizaciÃ³n de Performance

**Para MÃ¡ximo Rendimiento:**
```json
{
  "max_workers": 3,
  "delay_min": 1,
  "delay_max": 2,
  "headless": true
}
```

**Para MÃ¡xima Estabilidad:**
```json
{
  "max_workers": 1,
  "delay_min": 3,
  "delay_max": 6,
  "headless": true
}
```

## Estructura de Archivos Clave

```
scrapers_independientes/
â”œâ”€â”€ orchestrator.py              # ğŸš€ ORQUESTADOR PRINCIPAL V5
â”œâ”€â”€ run_complete_system.py       # Sistema alternativo
â”œâ”€â”€ run_scrapers_system.py       # Sistema legacy
â”œâ”€â”€ config.json                  # ConfiguraciÃ³n centralizada
â”œâ”€â”€ setup.py                     # Instalador automÃ¡tico
â”œâ”€â”€ EJECUTAR_SCRAPERS.bat       # Script Windows
â”œâ”€â”€ core/                        # Motor V5
â”‚   â”œâ”€â”€ base_scraper.py         # Clase base con ML
â”‚   â”œâ”€â”€ utils.py                # Utilidades compartidas
â”‚   â”œâ”€â”€ anti_detection_system.py # Anti-detecciÃ³n avanzado
â”‚   â””â”€â”€ emoji_support.py        # Soporte UTF-8 completo
â”œâ”€â”€ scrapers/                    # Scrapers especÃ­ficos V5
â”‚   â”œâ”€â”€ paris_scraper_v5_improved.py    # 15+ campos
â”‚   â”œâ”€â”€ paris_scraper_v5_port_integrated.py # IntegraciÃ³n PORT
â”‚   â”œâ”€â”€ ripley_scraper_v5_improved.py   # 18+ campos
â”‚   â”œâ”€â”€ falabella_scraper_v5_improved.py # 14+ campos
â”‚   â”œâ”€â”€ falabella_scraper_v5_parallel.py # VersiÃ³n paralela
â”‚   â”œâ”€â”€ hites_scraper_v5_improved.py    # 16+ campos
â”‚   â””â”€â”€ abcdin_scraper_v5_improved.py   # 17+ campos
â”œâ”€â”€ config/
â”‚   â””â”€â”€ retailers.json           # ConfiguraciÃ³n detallada
â””â”€â”€ resultados/                  # Archivos generados
    â”œâ”€â”€ *.xlsx                   # Excel con campos completos
    â”œâ”€â”€ *.json                   # Datos + metadatos
    â””â”€â”€ *.log                    # Logs con emojis
```

## Notas Importantes

- **ğŸ¯ Punto de Entrada Recomendado**: `orchestrator.py` con modo concurrent para mejor performance
- **ğŸ˜Š Emojis Obligatorios**: Todos los scripts fuerzan soporte UTF-8 y emojis nativos
- **ğŸ›¡ï¸ Anti-detecciÃ³n Activa**: Sistema robusto con rotaciones y delays inteligentes
- **ğŸ“Š Datos Completos**: 14-18 campos por retailer vs 5-8 bÃ¡sicos de sistemas anteriores
- **ğŸ”§ Mantenimiento Simple**: Sistema autocontenido sin dependencias externas complejas
- **âš¡ Performance Optimizada**: Modos concurrent/sequential para diferentes necesidades

El sistema estÃ¡ diseÃ±ado para ser completamente autÃ³nomo y funcional desde la primera ejecuciÃ³n, con capacidades avanzadas de extracciÃ³n de datos y soporte completo de emojis para mejor experiencia visual.

## Estado Actual de los Scrapers

### ğŸŸ¢ Scrapers Activos y Funcionales
SegÃºn el archivo `orchestrator.py`, los scrapers actualmente disponibles son:

- **Paris**: `paris_scraper_v5_port_integrated.py` (integrado con campos PORT)
- **Falabella**: `falabella_scraper_v5_parallel.py` (versiÃ³n paralela optimizada)  
- **AbcDin**: `abcdin_scraper_v5_improved.py` (campos completos)

### ğŸŸ¡ Scrapers en Desarrollo/Desactivados
- **Ripley**: Comentado temporalmente en orchestrator.py
- **Hites**: Comentado temporalmente en orchestrator.py

### ğŸ“Š ConfiguraciÃ³n de Retailers en config.json

SegÃºn la configuraciÃ³n actual:
- **Falabella**: âœ… Activo
- **Paris**: âœ… Activo  
- **Ripley**: âœ… Activo (configurado pero con navegador visible off-screen)
- **Hites**: âŒ Desactivado (`"activo": false`)
- **AbcDin**: âŒ Desactivado (`"activo": false`)
- **MercadoLibre**: âœ… Activo

**Nota**: Existe una discrepancia entre la configuraciÃ³n JSON y los scrapers importados en el orquestador. Para activar todos los scrapers, es necesario:
1. Activar los retailers desactivados en `config.json`
2. Descomentar las importaciones en `orchestrator.py`
3. Verificar que todos los archivos de scraper existan y funcionen correctamente