# ğŸš€ Sistema de Scrapers Independiente V5

[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-Private-red.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-Production%20Ready-green.svg)](README.md)

Sistema completo de scraping autÃ³nomo para 6 retailers chilenos principales. Funciona completamente independiente con anti-detecciÃ³n avanzada y exportaciÃ³n automÃ¡tica.

## ğŸ¯ CaracterÃ­sticas Principales

- **âœ… 6 Retailers**: Falabella, Paris, Ripley, Hites, AbcDin, MercadoLibre
- **âœ… Completamente Independiente**: No requiere sistema externo
- **âœ… Anti-detecciÃ³n Avanzada**: RotaciÃ³n UA, delays inteligentes, headers realistas
- **âœ… ExportaciÃ³n AutomÃ¡tica**: Excel individuales + reporte unificado
- **âœ… Soporte Emojis**: Logs visuales e intuitivos ğŸ˜Š
- **âœ… ConfiguraciÃ³n Flexible**: Activar/desactivar retailers individualmente
- **âœ… Sistema Robusto**: Manejo de errores y reintentos automÃ¡ticos

## ğŸš€ Inicio RÃ¡pido

### 1. InstalaciÃ³n AutomÃ¡tica
```bash
git clone https://github.com/Pachonchox/sistema-scrapers-independiente.git
cd sistema-scrapers-independiente
python setup.py
```

### 2. Ejecutar Sistema
```bash
# Todos los scrapers
python run_scrapers_system.py

# Scraper individual
python run_scrapers_system.py falabella

# Windows (un click)
EJECUTAR_SCRAPERS.bat
```

### 3. Ver Resultados
```bash
ls resultados/
```

## ğŸ“Š Retailers Soportados

| Retailer | Estado | ConfiguraciÃ³n Especial |
|----------|--------|------------------------|
| ğŸ›ï¸ **Falabella** | âœ… Activo | ConfiguraciÃ³n estÃ¡ndar |
| ğŸ›ï¸ **Paris** | âœ… Activo | Selectores PORT integrados |
| ğŸ›ï¸ **Ripley** | âœ… Activo | Navegador off-screen + scroll |
| ğŸ›ï¸ **Hites** | âœ… Activo | Optimizado para VTEX |
| ğŸ›ï¸ **AbcDin** | âœ… Activo | DOMContentLoaded wait |
| ğŸ›ï¸ **MercadoLibre** | âœ… Activo | ConfiguraciÃ³n estÃ¡ndar |

## âš™ï¸ ConfiguraciÃ³n

### config.json
```json
{
  "sistema": {
    "max_workers": 1,          // 1=secuencial, >1=paralelo
    "export_excel": true,      // Exportar Excel individuales
    "export_unified": true     // Crear reporte unificado
  },
  "retailers": {
    "falabella": {
      "activo": true,          // Activar/desactivar
      "max_productos": 100     // LÃ­mite de productos
    }
  }
}
```

### Anti-detecciÃ³n
- **User Agents**: 4+ navegadores reales rotando
- **Delays**: 2-5 segundos aleatorios
- **Headers**: Completos y realistas
- **Webdriver**: Completamente oculto
- **Reintentos**: 3 intentos automÃ¡ticos

## ğŸ“ Estructura del Proyecto

```
sistema-scrapers-independiente/
â”œâ”€â”€ ğŸš€ run_scrapers_system.py     # ARCHIVO PRINCIPAL
â”œâ”€â”€ âš™ï¸ config.json                # ConfiguraciÃ³n centralizada
â”œâ”€â”€ ğŸ”§ setup.py                   # Instalador automÃ¡tico
â”œâ”€â”€ ğŸ§ª test_system.py             # Sistema de pruebas
â”œâ”€â”€ ğŸ“‹ requirements.txt           # Dependencias
â”œâ”€â”€ ğŸ–¥ï¸ EJECUTAR_SCRAPERS.bat      # Script Windows
â”œâ”€â”€ ğŸ“– INSTRUCCIONES.md           # Manual completo
â”œâ”€â”€ core/                         # Motor principal
â”‚   â”œâ”€â”€ base_scraper.py          # Clase base scrapers
â”‚   â””â”€â”€ utils.py                 # Utilidades compartidas
â””â”€â”€ resultados/                   # Archivos generados
    â”œâ”€â”€ falabella_productos_*.xlsx
    â”œâ”€â”€ resumen_scraping_*.xlsx
    â””â”€â”€ scraping_*.log
```

## ğŸ›¡ï¸ CaracterÃ­sticas Anti-DetecciÃ³n

### Implementaciones
- âœ… **RotaciÃ³n User Agents**: 4+ navegadores reales
- âœ… **Delays Inteligentes**: Aleatorios entre 2-5s
- âœ… **Headers Completos**: Accept, Language, Encoding
- âœ… **Webdriver Ocultado**: Properties eliminadas
- âœ… **Viewport Realista**: 1920x1080
- âœ… **ConfiguraciÃ³n por Retailer**: Timeouts especÃ­ficos

### Especiales
- **Ripley**: Navegador visible off-screen (-2000, 0) + scroll obligatorio
- **AbcDin**: Espera DOM content loaded
- **Todos**: Reintentos automÃ¡ticos y timeouts personalizados

## ğŸ“Š Resultados y ExportaciÃ³n

### Archivos Generados
- **`retailer_productos_YYYYMMDD_HHMMSS.xlsx`**: Excel individual por retailer
- **`resumen_scraping_YYYYMMDD_HHMMSS.xlsx`**: Reporte unificado con:
  - Hoja "Resumen": EstadÃ­sticas por retailer
  - Hoja "Todos_Productos": Base de datos completa
  - Hojas individuales por retailer
- **`scraping_YYYYMMDD.log`**: Log completo con emojis

### Formato de Datos
```json
{
  "nombre": "Samsung Galaxy S24 256GB",
  "precio_texto": "$599.990",
  "precio_numero": 599990,
  "link": "https://...",
  "retailer": "falabella",
  "categoria": "smartphones",
  "timestamp": "2024-09-05T14:30:22"
}
```

## ğŸ§ª Testing y ValidaciÃ³n

### Pruebas AutomÃ¡ticas
```bash
# Test completo del sistema
python test_system.py

# Test scraper individual
python run_scrapers_system.py falabella
```

### Validaciones
- âœ… **Imports**: Todas las dependencias
- âœ… **ConfiguraciÃ³n**: ValidaciÃ³n completa config.json
- âœ… **Estructura**: Directorios y archivos necesarios
- âœ… **Scraper**: Prueba real de extracciÃ³n

## ğŸ”§ Troubleshooting

### Errores Comunes

**Python no encontrado**
```bash
# Instalar Python 3.8+ desde python.org
# Marcar "Add Python to PATH"
```

**Playwright falla**
```bash
pip install playwright
python -m playwright install chromium
```

**Sin productos extraÃ­dos**
- Verificar conexiÃ³n internet
- Reducir `max_productos` a 10 para prueba
- Revisar logs en `resultados/`

### Logs y Debugging
- ğŸ“„ **Logs**: `resultados/scraping_YYYYMMDD.log`
- ğŸ” **Niveles**: INFO, WARNING, ERROR, DEBUG
- ğŸ¨ **Emojis**: IdentificaciÃ³n visual rÃ¡pida

## ğŸ“ˆ OptimizaciÃ³n y Rendimiento

### Configuraciones Recomendadas

**Para Estabilidad**
```json
{
  "max_workers": 1,
  "delay_min": 3,
  "delay_max": 6,
  "headless": true
}
```

**Para Velocidad**
```json
{
  "max_workers": 2,
  "delay_min": 1,
  "delay_max": 3,
  "headless": true
}
```

### MÃ©tricas
- **Velocidad**: ~10-20 productos/minuto por scraper
- **Ã‰xito**: 85-95% tasa de Ã©xito tÃ­pica
- **Memoria**: <500MB uso tÃ­pico
- **CPU**: Uso moderado durante ejecuciÃ³n

## ğŸ”„ Mantenimiento

### Actualizar Selectores
Si un scraper deja de funcionar:
1. Verificar pÃ¡gina web manualmente
2. Inspeccionar elementos (F12 en navegador)
3. Actualizar selectores en `config.json`
4. Probar: `python test_system.py`

### Monitoreo
```bash
# Contar archivos generados
ls resultados/*.xlsx | wc -l

# Ver Ãºltimos logs
tail -f resultados/scraping_$(date +%Y%m%d).log
```

## ğŸŒŸ Uso Avanzado

### ProgramaciÃ³n AutomÃ¡tica
```bash
# Windows Task Scheduler
schtasks /create /tn "Scrapers" /tr "python run_scrapers_system.py" /sc daily /st 09:00

# Linux Cron
0 9 * * * cd /path/to/scrapers && python3 run_scrapers_system.py
```

### IntegraciÃ³n API
El sistema puede integrarse fÃ¡cilmente con APIs externas modificando las funciones de exportaciÃ³n en `core/utils.py`.

## ğŸ“ Soporte y Contribuciones

### Reportar Issues
Para reportar problemas, incluir:
- VersiÃ³n Python: `python --version`
- Sistema operativo
- Error completo del log
- ConfiguraciÃ³n utilizada

### Desarrollo
- **CÃ³digo**: Seguir PEP 8
- **Commits**: Usar emojis y descripciones claras
- **Testing**: Probar con `test_system.py` antes de commit

## ğŸ“„ Licencia

Este proyecto es privado y confidencial. Todos los derechos reservados.

---

## ğŸ‰ Estado del Proyecto

**âœ… PRODUCCIÃ“N**: Sistema completamente funcional y probado.

**Ãšltima actualizaciÃ³n**: Septiembre 2024  
**VersiÃ³n**: 1.0.0  
**Estado**: Mantenimiento activo