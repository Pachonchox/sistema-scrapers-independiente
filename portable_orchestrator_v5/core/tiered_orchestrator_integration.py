#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ğŸ¯ INTEGRADOR ORQUESTADOR TIER INTELIGENTE V5
============================================

Integra el sistema de tiers inteligente con el orquestador V5 robusto existente,
reemplazando los ciclos continuos por schedulling basado en tiers.

CaracterÃ­sticas:
- ğŸšï¸ IntegraciÃ³n transparente con orquestador existente
- â° Scheduling inteligente basado en tiers (2h/6h/24h)
- ğŸ­ Anti-detecciÃ³n automÃ¡tica integrada
- ğŸ“Š MÃ©tricas y estadÃ­sticas unificadas
- ğŸ”„ RotaciÃ³n de proxies y user agents
- ğŸ² AleatorizaciÃ³n de patrones de scraping

Autor: Sistema V5 Production
Fecha: 03/09/2025
"""

import asyncio
import logging
import signal
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Callable
from pathlib import Path
import sys
import os
import json

# AÃ±adir paths
sys.path.append(str(Path(__file__).parent.parent.parent))

from .intelligent_scheduler import IntelligentScheduler
from .advanced_tier_manager import AdvancedTierManager
from .anti_detection_system import AntiDetectionSystem

logger = logging.getLogger(__name__)

class TieredOrchestratorIntegration:
    """
    ğŸ¯ Integrador que conecta el sistema de tiers inteligente 
    con el orquestador V5 existente
    """
    
    def __init__(self, orchestrator_instance):
        """
        Inicializar integraciÃ³n con instancia del orquestador
        
        Args:
            orchestrator_instance: Instancia de OrchestratorV5Robust
        """
        self.orchestrator = orchestrator_instance
        self.scheduler = IntelligentScheduler()
        self.running = False
        self.integration_stats = {
            'tier_executions': {'critical': 0, 'important': 0, 'tracking': 0},
            'total_scraping_sessions': 0,
            'anti_detection_activations': 0,
            'proxy_rotations': 0,
            'user_agent_changes': 0,
            'pattern_breaks': 0,
            'errors_handled': 0
        }
        
        logger.info("ğŸ¯ TieredOrchestratorIntegration inicializado")
        
        # Configurar handlers de seÃ±ales
        self._setup_signal_handlers()
    
    def _setup_signal_handlers(self):
        """Configurar manejo de seÃ±ales para shutdown graceful"""
        def signal_handler(signum, frame):
            logger.info(f"ğŸ“¢ SeÃ±al recibida: {signum}")
            asyncio.create_task(self.stop())
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
    
    async def start(self, continuous: bool = True, max_runtime_hours: int = None):
        """
        ğŸš€ Iniciar el sistema integrado de tiers
        
        Args:
            continuous: Si debe ejecutar continuamente
            max_runtime_hours: MÃ¡ximo tiempo de ejecuciÃ³n en horas
        """
        logger.info("ğŸš€ Iniciando sistema de orquestaciÃ³n por tiers...")
        
        self.running = True
        start_time = datetime.now()
        
        try:
            # Inicializar scheduler inteligente
            await self.scheduler.start()
            
            # Configurar callback de scraping personalizado
            await self._setup_scraping_callbacks()
            
            logger.info("âœ… Sistema de tiers iniciado correctamente")
            
            # Bucle principal - delegamos al scheduler inteligente
            while self.running and continuous:
                # El scheduler maneja toda la lÃ³gica de timing y ejecuciÃ³n
                await asyncio.sleep(1.0)  # VerificaciÃ³n mÃ­nima
                
                # Verificar lÃ­mite de tiempo si estÃ¡ configurado
                if max_runtime_hours:
                    elapsed = (datetime.now() - start_time).total_seconds() / 3600
                    if elapsed >= max_runtime_hours:
                        logger.info(f"â° LÃ­mite de tiempo alcanzado: {max_runtime_hours}h")
                        break
                
                # Verificar si el scheduler estÃ¡ activo
                if not self.scheduler.running:
                    logger.warning("âš ï¸ Scheduler inteligente se detuvo, reiniciando...")
                    await self.scheduler.start()
            
            # Si no es continuo, ejecutar una sola iteraciÃ³n de todos los tiers
            if not continuous:
                await self._execute_single_tier_cycle()
        
        except Exception as e:
            logger.error(f"âŒ Error en sistema de tiers: {e}")
            self.integration_stats['errors_handled'] += 1
            raise
        
        finally:
            await self.stop()
    
    async def _setup_scraping_callbacks(self):
        """ğŸ”— Configurar callbacks de scraping para el scheduler"""
        
        async def tier_scraping_callback(tier_name: str, retailers: List[str], 
                                       categories: List[str], pages: int):
            """
            Callback personalizado que ejecuta scraping usando el orquestador existente
            """
            logger.info(f"ğŸ“Š Ejecutando scraping tier {tier_name}: "
                       f"{retailers} - {categories} - {pages} pÃ¡ginas")
            
            try:
                # Actualizar stats de integraciÃ³n
                self.integration_stats['tier_executions'][tier_name] += 1
                self.integration_stats['total_scraping_sessions'] += 1
                
                # Configurar temporalmente el orquestador para esta ejecuciÃ³n
                original_config = self.orchestrator.config.copy()
                
                # Adaptar configuraciÃ³n para la ejecuciÃ³n de tier especÃ­fica
                self.orchestrator.config.update({
                    'retailers': retailers,
                    'categories': categories if categories else original_config.get('categories', {}),
                    'max_pages': pages,
                    'tier_mode': True,
                    'current_tier': tier_name
                })
                
                # Ejecutar el ciclo de scraping del orquestador
                cycle_results = await self._execute_orchestrator_cycle(retailers, categories, pages)
                
                # Restaurar configuraciÃ³n original
                self.orchestrator.config = original_config
                
                logger.info(f"âœ… Tier {tier_name} completado: {cycle_results}")
                
                return cycle_results
                
            except Exception as e:
                logger.error(f"âŒ Error en tier {tier_name}: {e}")
                self.integration_stats['errors_handled'] += 1
                return {'success': False, 'error': str(e), 'products_processed': 0}
        
        # Registrar callback en el scheduler
        self.scheduler.set_scraping_callback(tier_scraping_callback)
        
        # Configurar callback de anti-detecciÃ³n
        async def anti_detection_callback(action: str, details: Dict[str, Any]):
            """Callback para eventos de anti-detecciÃ³n"""
            logger.debug(f"ğŸ­ Anti-detecciÃ³n: {action} - {details}")
            
            if action == 'proxy_rotation':
                self.integration_stats['proxy_rotations'] += 1
            elif action == 'user_agent_change':
                self.integration_stats['user_agent_changes'] += 1
            elif action == 'pattern_break':
                self.integration_stats['pattern_breaks'] += 1
            
            self.integration_stats['anti_detection_activations'] += 1
        
        self.scheduler.anti_detection.set_callback(anti_detection_callback)
    
    async def _execute_orchestrator_cycle(self, retailers: List[str], 
                                        categories: List[str], pages: int) -> Dict[str, Any]:
        """
        ğŸ”„ Ejecutar un ciclo de scraping usando el orquestrador existente
        """
        results = {
            'success': True,
            'products_processed': 0,
            'retailers_processed': [],
            'errors': [],
            'start_time': datetime.now(),
            'end_time': None
        }
        
        try:
            for retailer in retailers:
                if not self.running:
                    break
                
                logger.info(f"ğŸ›ï¸ Procesando retailer: {retailer}")
                
                try:
                    # Obtener scraper para este retailer
                    scraper = await self.orchestrator.get_scraper(retailer)
                    
                    if not scraper:
                        logger.warning(f"âš ï¸ No se pudo obtener scraper para {retailer}")
                        results['errors'].append(f"Scraper no disponible para {retailer}")
                        continue
                    
                    # Obtener categorÃ­as para este retailer
                    retailer_categories = self.orchestrator.config.get('categories', {}).get(retailer, [])
                    if categories:
                        # Filtrar solo las categorÃ­as solicitadas que existen para este retailer
                        retailer_categories = [cat for cat in categories if cat in retailer_categories]
                    
                    if not retailer_categories:
                        logger.warning(f"âš ï¸ No hay categorÃ­as vÃ¡lidas para {retailer}")
                        continue
                    
                    # Procesar cada categorÃ­a
                    for category in retailer_categories:
                        if not self.running:
                            break
                        
                        logger.info(f"ğŸ“‚ Procesando categorÃ­a: {category}")
                        
                        # Ejecutar scraping para esta categorÃ­a
                        category_results = await scraper.scrape_category(
                            category=category,
                            max_pages=pages,
                            timeout=300  # 5 minutos timeout por categorÃ­a
                        )
                        
                        if category_results and category_results.products:
                            # Procesar productos usando el orquestador
                            processed = await self.orchestrator.process_scraped_data(
                                retailer, category_results
                            )
                            
                            results['products_processed'] += len(category_results.products)
                            logger.info(f"  âœ… {len(category_results.products)} productos procesados")
                        
                        # Aplicar delay entre categorÃ­as (anti-detecciÃ³n)
                        await self.scheduler.anti_detection.apply_human_delay('category_change')
                    
                    results['retailers_processed'].append(retailer)
                    
                    # Delay entre retailers
                    if len(retailers) > 1:
                        await self.scheduler.anti_detection.apply_human_delay('retailer_change')
                
                except Exception as e:
                    error_msg = f"Error procesando {retailer}: {str(e)}"
                    logger.error(f"âŒ {error_msg}")
                    results['errors'].append(error_msg)
                    self.integration_stats['errors_handled'] += 1
            
            results['end_time'] = datetime.now()
            
            # Ejecutar detecciÃ³n de arbitraje si estÃ¡ habilitada
            if self.orchestrator.config.get('arbitrage_enabled', False):
                await self.orchestrator.detect_arbitrage_opportunities()
            
        except Exception as e:
            results['success'] = False
            results['errors'].append(str(e))
            logger.error(f"âŒ Error general en ciclo de scraping: {e}")
        
        return results
    
    async def _execute_single_tier_cycle(self):
        """ğŸ”„ Ejecutar una sola iteraciÃ³n de todos los tiers (modo no continuo)"""
        logger.info("ğŸ”„ Ejecutando ciclo Ãºnico de todos los tiers...")
        
        # Ejecutar tier crÃ­tico
        await self.scheduler._execute_tier_cycle('critical')
        
        # PequeÃ±o delay entre tiers
        await asyncio.sleep(60)  # 1 minuto entre tiers
        
        # Ejecutar tier importante
        await self.scheduler._execute_tier_cycle('important')
        
        await asyncio.sleep(60)
        
        # Ejecutar tier de tracking
        await self.scheduler._execute_tier_cycle('tracking')
        
        logger.info("âœ… Ciclo Ãºnico de tiers completado")
    
    async def stop(self):
        """ğŸ›‘ Detener el sistema de tiers de forma graceful"""
        logger.info("ğŸ›‘ Deteniendo sistema de tiers...")
        
        self.running = False
        
        if self.scheduler and hasattr(self.scheduler, 'stop'):
            await self.scheduler.stop()
        elif self.scheduler:
            # Si no tiene mÃ©todo stop, solo marcamos como no running
            self.scheduler.running = False
        
        # Mostrar estadÃ­sticas finales
        self._log_final_stats()
        
        logger.info("âœ… Sistema de tiers detenido correctamente")
    
    def _log_final_stats(self):
        """ğŸ“Š Mostrar estadÃ­sticas finales de la integraciÃ³n"""
        logger.info("ğŸ“Š ESTADÃSTICAS FINALES DE INTEGRACIÃ“N:")
        logger.info(f"  ğŸ¯ Ejecuciones por tier: {self.integration_stats['tier_executions']}")
        logger.info(f"  ğŸ“ˆ Total sesiones de scraping: {self.integration_stats['total_scraping_sessions']}")
        logger.info(f"  ğŸ­ Activaciones anti-detecciÃ³n: {self.integration_stats['anti_detection_activations']}")
        logger.info(f"  ğŸ”„ Rotaciones de proxy: {self.integration_stats['proxy_rotations']}")
        logger.info(f"  ğŸª Cambios de user agent: {self.integration_stats['user_agent_changes']}")
        logger.info(f"  ğŸ² Rupturas de patrÃ³n: {self.integration_stats['pattern_breaks']}")
        logger.info(f"  âŒ Errores manejados: {self.integration_stats['errors_handled']}")
    
    def get_integration_status(self) -> Dict[str, Any]:
        """ğŸ“Š Obtener estado actual de la integraciÃ³n"""
        return {
            'running': self.running,
            'scheduler_running': self.scheduler.running if self.scheduler else False,
            'stats': self.integration_stats.copy(),
            'scheduler_stats': self.scheduler.get_status() if self.scheduler else {},
            'current_time': datetime.now(),
        }


async def main():
    """ğŸš€ FunciÃ³n principal para pruebas de integraciÃ³n"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    logger.info("ğŸ§ª Iniciando prueba de integraciÃ³n de tiers...")
    
    # Para pruebas, crear una instancia mock del orquestador
    class MockOrchestrator:
        def __init__(self):
            self.config = {
                'retailers': ['ripley', 'falabella'],
                'categories': {
                    'ripley': ['celulares', 'tablets'],
                    'falabella': ['celulares', 'computadores']
                },
                'arbitrage_enabled': True
            }
        
        async def get_scraper(self, retailer: str):
            logger.info(f"ğŸ›ï¸ Mock: Obteniendo scraper para {retailer}")
            return None  # Mock
        
        async def process_scraped_data(self, retailer: str, data):
            logger.info(f"ğŸ“Š Mock: Procesando datos de {retailer}")
            return {'processed': True}
        
        async def detect_arbitrage_opportunities(self):
            logger.info("ğŸ’° Mock: Detectando oportunidades de arbitraje")
    
    mock_orchestrator = MockOrchestrator()
    integration = TieredOrchestratorIntegration(mock_orchestrator)
    
    try:
        # Ejecutar prueba por 2 minutos
        await integration.start(continuous=True, max_runtime_hours=0.033)  # ~2 minutos
        
    except KeyboardInterrupt:
        logger.info("â¹ï¸ Prueba interrumpida por usuario")
    
    finally:
        await integration.stop()


if __name__ == "__main__":
    asyncio.run(main())