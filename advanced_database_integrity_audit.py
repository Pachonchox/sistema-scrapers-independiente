#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ğŸ” AUDITORÃA AVANZADA DE INTEGRIDAD DE BASE DE DATOS
==================================================

Sistema completo de auditorÃ­a que verifica:
âœ… Duplicados por mÃºltiples mÃ©todos (no solo SKU interno)
âœ… Integridad completa de datos
âœ… AnÃ¡lisis de similitud textual
âœ… DetecciÃ³n de productos repetidos por patrones
âœ… ValidaciÃ³n de consistencia completa
âœ… GeneraciÃ³n de reportes detallados con emojis

Autor: Sistema V5 Production
Fecha: 04/09/2025
"""

import os
import sys
import psycopg2
import psycopg2.extras
from datetime import datetime, timedelta
from pathlib import Path
from difflib import SequenceMatcher
import re
from collections import defaultdict
import json
from typing import Dict, List, Tuple, Any

# Configurar soporte completo de emojis
sys.path.append(str(Path(__file__).parent))
from portable_orchestrator_v5.core.emoji_support import force_emoji_support
force_emoji_support()

# Cargar configuraciÃ³n
from dotenv import load_dotenv
load_dotenv()

class AdvancedDatabaseIntegrityAuditor:
    """ğŸ” Auditor avanzado de integridad de base de datos con detecciÃ³n mÃºltiple de duplicados"""
    
    def __init__(self):
        """Inicializar auditor avanzado"""
        print("ğŸš€ Inicializando Auditor Avanzado de Integridad...")
        
        # ParÃ¡metros de conexiÃ³n
        self.conn_params = {
            'host': os.getenv('PGHOST', 'localhost'),
            'port': int(os.getenv('PGPORT', '5432')),
            'database': os.getenv('PGDATABASE', 'orchestrator'),
            'user': os.getenv('PGUSER', 'postgres'),
            'password': os.getenv('PGPASSWORD', 'postgres')
        }
        
        try:
            self.conn = psycopg2.connect(**self.conn_params)
            self.conn.autocommit = True
            self.cursor = self.conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
            print(f"âœ… Conectado a PostgreSQL: {self.conn_params['host']}:{self.conn_params['port']}")
        except Exception as e:
            print(f"âŒ Error conectando a PostgreSQL: {e}")
            raise
        
        # Contadores de resultados
        self.critical_violations = []
        self.warnings = []
        self.duplicate_groups = []
        self.stats = {}
        
        # ConfiguraciÃ³n de similitud
        self.similarity_threshold = 0.85  # 85% similitud
        self.name_similarity_threshold = 0.90  # 90% similitud en nombres
        
    def normalize_text(self, text: str) -> str:
        """ğŸ”¤ Normalizar texto para comparaciÃ³n"""
        if not text:
            return ""
        
        # Convertir a minÃºsculas
        text = text.lower().strip()
        
        # Remover caracteres especiales y espacios extra
        text = re.sub(r'[^\w\s]', '', text)
        text = re.sub(r'\s+', ' ', text)
        
        # Normalizar palabras comunes
        replacements = {
            'smartphone': 'cel',
            'celular': 'cel',
            'television': 'tv',
            'televisor': 'tv',
            'notebook': 'laptop',
            'computador': 'pc',
            'computadora': 'pc',
            'tablet': 'tab',
            'electrodomestico': 'electro'
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        return text.strip()
    
    def calculate_text_similarity(self, text1: str, text2: str) -> float:
        """ğŸ“ Calcular similitud entre dos textos"""
        norm1 = self.normalize_text(text1)
        norm2 = self.normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
        
        return SequenceMatcher(None, norm1, norm2).ratio()
    
    def extract_product_specs(self, name: str) -> Dict[str, str]:
        """ğŸ”§ Extraer especificaciones del nombre del producto"""
        specs = {
            'brand': '',
            'model': '',
            'storage': '',
            'ram': '',
            'screen_size': '',
            'color': ''
        }
        
        if not name:
            return specs
        
        name_lower = name.lower()
        
        # Extraer marca (primeras palabras comunes)
        brands = ['samsung', 'apple', 'huawei', 'xiaomi', 'lg', 'sony', 'hp', 'lenovo', 'asus', 'dell']
        for brand in brands:
            if brand in name_lower:
                specs['brand'] = brand
                break
        
        # Extraer almacenamiento
        storage_match = re.search(r'(\d+)\s?(gb|tb)', name_lower)
        if storage_match:
            specs['storage'] = f"{storage_match.group(1)}{storage_match.group(2)}"
        
        # Extraer RAM
        ram_match = re.search(r'(\d+)\s?gb.*ram', name_lower)
        if ram_match:
            specs['ram'] = f"{ram_match.group(1)}gb"
        
        # Extraer tamaÃ±o pantalla
        screen_match = re.search(r'(\d+\.?\d*)\s?pulgadas?|(\d+\.?\d*)[""]', name_lower)
        if screen_match:
            size = screen_match.group(1) or screen_match.group(2)
            specs['screen_size'] = f"{size}inch"
        
        return specs
    
    def check_duplicate_by_codigo_interno(self):
        """ğŸ” 1. Verificar duplicados por cÃ³digo interno (mÃ©todo base)"""
        print("\n" + "ğŸ”" + "="*70 + "ğŸ”")
        print("1ï¸âƒ£ VERIFICANDO DUPLICADOS POR CÃ“DIGO INTERNO")
        print("ğŸ”" + "="*70 + "ğŸ”")
        
        self.cursor.execute("""
            SELECT codigo_interno, COUNT(*) as count
            FROM master_productos
            GROUP BY codigo_interno
            HAVING COUNT(*) > 1
            ORDER BY COUNT(*) DESC
        """)
        
        duplicates = self.cursor.fetchall()
        
        if duplicates:
            self.critical_violations.append(f"ğŸ’¥ {len(duplicates)} cÃ³digos internos duplicados")
            print(f"âŒ VIOLACIÃ“N CRÃTICA: {len(duplicates)} cÃ³digos internos duplicados")
            
            for dup in duplicates[:5]:
                print(f"   ğŸ“¦ {dup['codigo_interno']}: {dup['count']} ocurrencias")
                
                # Mostrar detalles de los duplicados
                self.cursor.execute("""
                    SELECT nombre, retailer, link, created_at
                    FROM master_productos 
                    WHERE codigo_interno = %s
                """, (dup['codigo_interno'],))
                
                details = self.cursor.fetchall()
                for detail in details:
                    print(f"      ğŸª {detail['retailer']}: {detail['nombre'][:50]}...")
                    print(f"         ğŸ“… {detail['created_at']} | ğŸ”— {detail['link'][:50]}...")
                print()
        else:
            print("âœ… NO hay cÃ³digos internos duplicados")
    
    def check_duplicate_by_link(self):
        """ğŸ”— 2. Verificar duplicados por link/URL"""
        print("\n" + "ğŸ”—" + "="*70 + "ğŸ”—")
        print("2ï¸âƒ£ VERIFICANDO DUPLICADOS POR LINK/URL")
        print("ğŸ”—" + "="*70 + "ğŸ”—")
        
        self.cursor.execute("""
            SELECT link, COUNT(*) as count, 
                   array_agg(codigo_interno) as codigos,
                   array_agg(retailer) as retailers
            FROM master_productos
            WHERE link IS NOT NULL AND link != ''
            GROUP BY link
            HAVING COUNT(*) > 1
            ORDER BY COUNT(*) DESC
            LIMIT 20
        """)
        
        link_duplicates = self.cursor.fetchall()
        
        if link_duplicates:
            self.critical_violations.append(f"ğŸ”— {len(link_duplicates)} links duplicados")
            print(f"âŒ PROBLEMA: {len(link_duplicates)} links duplicados encontrados")
            
            for dup in link_duplicates:
                print(f"   ğŸ”— Link: {dup['link'][:60]}...")
                print(f"   ğŸ“¦ CÃ³digos: {', '.join(dup['codigos'])}")
                print(f"   ğŸª Retailers: {', '.join(set(dup['retailers']))}")
                print()
        else:
            print("âœ… NO hay links duplicados")
    
    def check_duplicate_by_name_similarity(self):
        """ğŸ“ 3. Verificar duplicados por similitud de nombres"""
        print("\n" + "ğŸ“" + "="*70 + "ğŸ“")
        print("3ï¸âƒ£ VERIFICANDO DUPLICADOS POR SIMILITUD DE NOMBRES")
        print("ğŸ“" + "="*70 + "ğŸ“")
        
        print("â³ Cargando productos para anÃ¡lisis de similitud...")
        
        # Obtener productos con informaciÃ³n bÃ¡sica
        self.cursor.execute("""
            SELECT codigo_interno, nombre, retailer, marca, categoria
            FROM master_productos
            WHERE nombre IS NOT NULL AND LENGTH(nombre) > 10
            ORDER BY retailer, categoria
        """)
        
        products = self.cursor.fetchall()
        print(f"ğŸ” Analizando {len(products):,} productos...")
        
        similar_groups = []
        processed = set()
        
        # Comparar productos por similitud de nombres
        for i, product1 in enumerate(products):
            if product1['codigo_interno'] in processed:
                continue
                
            similar_group = [product1]
            processed.add(product1['codigo_interno'])
            
            # Comparar con productos restantes
            for j, product2 in enumerate(products[i+1:], i+1):
                if product2['codigo_interno'] in processed:
                    continue
                
                # Calcular similitud
                similarity = self.calculate_text_similarity(
                    product1['nombre'], 
                    product2['nombre']
                )
                
                # Si son muy similares, agregar al grupo
                if similarity >= self.name_similarity_threshold:
                    similar_group.append(product2)
                    processed.add(product2['codigo_interno'])
            
            # Si encontramos un grupo de similares, guardarlo
            if len(similar_group) > 1:
                similar_groups.append(similar_group)
            
            # Progreso cada 1000 productos
            if (i + 1) % 1000 == 0:
                print(f"   ğŸ“Š Procesados {i+1:,}/{len(products):,} productos...")
        
        if similar_groups:
            self.warnings.append(f"ğŸ” {len(similar_groups)} grupos de productos con nombres similares")
            print(f"âš ï¸ ENCONTRADOS: {len(similar_groups)} grupos de productos con nombres similares")
            
            for idx, group in enumerate(similar_groups[:10]):
                print(f"\n   ğŸ“¦ Grupo {idx+1} ({len(group)} productos similares):")
                for product in group:
                    print(f"      ğŸª {product['retailer']} | {product['codigo_interno']}")
                    print(f"         ğŸ“ {product['nombre'][:60]}...")
                
                if idx < len(similar_groups) - 1:
                    print(f"      âš–ï¸ Similitud: {self.calculate_text_similarity(group[0]['nombre'], group[1]['nombre']):.2%}")
                    
            self.duplicate_groups = similar_groups
        else:
            print("âœ… NO se encontraron nombres significativamente similares")
    
    def check_duplicate_by_specs(self):
        """ğŸ”§ 4. Verificar duplicados por especificaciones tÃ©cnicas"""
        print("\n" + "ğŸ”§" + "="*70 + "ğŸ”§")
        print("4ï¸âƒ£ VERIFICANDO DUPLICADOS POR ESPECIFICACIONES")
        print("ğŸ”§" + "="*70 + "ğŸ”§")
        
        # Obtener productos con especificaciones
        self.cursor.execute("""
            SELECT codigo_interno, nombre, marca, storage, ram, screen, categoria, retailer
            FROM master_productos
            WHERE marca IS NOT NULL 
            AND (storage IS NOT NULL OR ram IS NOT NULL OR screen IS NOT NULL)
        """)
        
        products_with_specs = self.cursor.fetchall()
        print(f"ğŸ” Analizando {len(products_with_specs):,} productos con especificaciones...")
        
        # Agrupar por especificaciones similares
        spec_groups = defaultdict(list)
        
        for product in products_with_specs:
            # Crear clave Ãºnica basada en especificaciones
            spec_key = f"{product.get('marca', '').lower()}|" + \
                      f"{product.get('storage', 'N/A')}|" + \
                      f"{product.get('ram', 'N/A')}|" + \
                      f"{product.get('screen', 'N/A')}|" + \
                      f"{product.get('categoria', 'N/A').lower()}"
            
            spec_groups[spec_key].append(product)
        
        # Encontrar grupos con mÃºltiples productos
        duplicate_spec_groups = {k: v for k, v in spec_groups.items() if len(v) > 1}
        
        if duplicate_spec_groups:
            total_duplicates = sum(len(group) for group in duplicate_spec_groups.values())
            self.warnings.append(f"ğŸ”§ {len(duplicate_spec_groups)} grupos con especificaciones idÃ©nticas")
            print(f"âš ï¸ ENCONTRADOS: {len(duplicate_spec_groups)} grupos con especificaciones idÃ©nticas")
            print(f"   ğŸ“Š Total productos involucrados: {total_duplicates}")
            
            for idx, (spec_key, group) in enumerate(list(duplicate_spec_groups.items())[:5]):
                print(f"\n   ğŸ”§ Grupo {idx+1} - Especificaciones: {spec_key}")
                for product in group:
                    print(f"      ğŸª {product['retailer']} | {product['codigo_interno']}")
                    print(f"         ğŸ“ {product['nombre'][:50]}...")
        else:
            print("âœ… NO se encontraron duplicados por especificaciones")
    
    def check_cross_retailer_duplicates(self):
        """ğŸª 5. Verificar duplicados entre retailers (mismo producto en mÃºltiples tiendas)"""
        print("\n" + "ğŸª" + "="*70 + "ğŸª")
        print("5ï¸âƒ£ VERIFICANDO DUPLICADOS ENTRE RETAILERS")
        print("ğŸª" + "="*70 + "ğŸª")
        
        self.cursor.execute("""
            WITH normalized_products AS (
                SELECT 
                    codigo_interno,
                    LOWER(REGEXP_REPLACE(nombre, '[^a-zA-Z0-9]', ' ', 'g')) as normalized_name,
                    marca,
                    storage,
                    retailer,
                    nombre as original_name
                FROM master_productos
                WHERE marca IS NOT NULL
            )
            SELECT 
                marca,
                normalized_name,
                array_agg(DISTINCT retailer) as retailers,
                array_agg(codigo_interno) as codigos,
                array_agg(original_name) as nombres,
                COUNT(DISTINCT retailer) as retailer_count
            FROM normalized_products
            GROUP BY marca, normalized_name
            HAVING COUNT(DISTINCT retailer) > 1
            ORDER BY COUNT(DISTINCT retailer) DESC
            LIMIT 20
        """)
        
        cross_retailer_duplicates = self.cursor.fetchall()
        
        if cross_retailer_duplicates:
            print(f"ğŸ” ENCONTRADOS: {len(cross_retailer_duplicates)} productos en mÃºltiples retailers")
            
            for dup in cross_retailer_duplicates:
                print(f"\n   ğŸ·ï¸ Marca: {dup['marca']} | Retailers: {len(dup['retailers'])}")
                print(f"   ğŸª Tiendas: {', '.join(dup['retailers'])}")
                print(f"   ğŸ“ Nombre ejemplo: {dup['nombres'][0][:60]}...")
                print(f"   ğŸ“¦ CÃ³digos: {len(dup['codigos'])} productos")
                
            self.stats['cross_retailer_duplicates'] = len(cross_retailer_duplicates)
        else:
            print("âœ… NO se encontraron productos duplicados entre retailers")
    
    def analyze_price_consistency(self):
        """ğŸ’° 6. Analizar consistencia de precios"""
        print("\n" + "ğŸ’°" + "="*70 + "ğŸ’°")
        print("6ï¸âƒ£ ANALIZANDO CONSISTENCIA DE PRECIOS")
        print("ğŸ’°" + "="*70 + "ğŸ’°")
        
        # Verificar precios invÃ¡lidos
        self.cursor.execute("""
            SELECT 
                COUNT(*) as total_invalid,
                COUNT(CASE WHEN precio_normal <= 0 THEN 1 END) as precio_normal_invalid,
                COUNT(CASE WHEN precio_oferta > precio_normal THEN 1 END) as oferta_mayor,
                COUNT(CASE WHEN precio_tarjeta > precio_normal THEN 1 END) as tarjeta_mayor
            FROM master_precios
            WHERE precio_normal <= 0 
               OR (precio_oferta > precio_normal AND precio_oferta IS NOT NULL)
               OR (precio_tarjeta > precio_normal AND precio_tarjeta IS NOT NULL)
        """)
        
        price_issues = self.cursor.fetchone()
        
        if price_issues and price_issues['total_invalid'] > 0:
            self.critical_violations.append(f"ğŸ’° {price_issues['total_invalid']} registros con precios invÃ¡lidos")
            print(f"âŒ PROBLEMAS DE PRECIOS:")
            print(f"   ğŸ’¸ Precios normales â‰¤ 0: {price_issues['precio_normal_invalid']}")
            print(f"   ğŸ”º Oferta > Normal: {price_issues['oferta_mayor']}")
            print(f"   ğŸ”º Tarjeta > Normal: {price_issues['tarjeta_mayor']}")
        else:
            print("âœ… Precios consistentes")
        
        # Verificar constraint diario
        self.cursor.execute("""
            SELECT codigo_interno, fecha, COUNT(*) as registros
            FROM master_precios
            GROUP BY codigo_interno, fecha
            HAVING COUNT(*) > 1
            ORDER BY COUNT(*) DESC
            LIMIT 5
        """)
        
        daily_violations = self.cursor.fetchall()
        
        if daily_violations:
            self.critical_violations.append(f"ğŸ“… {len(daily_violations)} violaciones de constraint diario")
            print(f"âŒ VIOLACIÃ“N CONSTRAINT DIARIO:")
            for violation in daily_violations:
                print(f"   ğŸ“¦ {violation['codigo_interno']}: {violation['registros']} registros el {violation['fecha']}")
        else:
            print("âœ… Constraint diario respetado (1 precio/producto/dÃ­a)")
    
    def analyze_data_quality(self):
        """ğŸ¯ 7. AnÃ¡lisis de calidad de datos"""
        print("\n" + "ğŸ¯" + "="*70 + "ğŸ¯")
        print("7ï¸âƒ£ ANÃLISIS DE CALIDAD DE DATOS")
        print("ğŸ¯" + "="*70 + "ğŸ¯")
        
        # Productos sin informaciÃ³n bÃ¡sica
        self.cursor.execute("""
            SELECT 
                COUNT(*) as total_productos,
                COUNT(CASE WHEN nombre IS NULL OR LENGTH(TRIM(nombre)) = 0 THEN 1 END) as sin_nombre,
                COUNT(CASE WHEN marca IS NULL OR LENGTH(TRIM(marca)) = 0 THEN 1 END) as sin_marca,
                COUNT(CASE WHEN categoria IS NULL OR LENGTH(TRIM(categoria)) = 0 THEN 1 END) as sin_categoria,
                COUNT(CASE WHEN link IS NULL OR LENGTH(TRIM(link)) = 0 THEN 1 END) as sin_link
            FROM master_productos
        """)
        
        quality_stats = self.cursor.fetchone()
        
        print(f"ğŸ“Š ESTADÃSTICAS DE CALIDAD:")
        print(f"   ğŸ“¦ Total productos: {quality_stats['total_productos']:,}")
        print(f"   ğŸ“ Sin nombre: {quality_stats['sin_nombre']:,} ({quality_stats['sin_nombre']/quality_stats['total_productos']*100:.1f}%)")
        print(f"   ğŸ·ï¸ Sin marca: {quality_stats['sin_marca']:,} ({quality_stats['sin_marca']/quality_stats['total_productos']*100:.1f}%)")
        print(f"   ğŸ“‚ Sin categorÃ­a: {quality_stats['sin_categoria']:,} ({quality_stats['sin_categoria']/quality_stats['total_productos']*100:.1f}%)")
        print(f"   ğŸ”— Sin link: {quality_stats['sin_link']:,} ({quality_stats['sin_link']/quality_stats['total_productos']*100:.1f}%)")
        
        # Identificar posibles problemas
        quality_threshold = 0.05  # 5%
        quality_issues = []
        
        if quality_stats['sin_nombre'] / quality_stats['total_productos'] > quality_threshold:
            quality_issues.append(f"Alto porcentaje sin nombre: {quality_stats['sin_nombre']/quality_stats['total_productos']*100:.1f}%")
            
        if quality_stats['sin_marca'] / quality_stats['total_productos'] > quality_threshold:
            quality_issues.append(f"Alto porcentaje sin marca: {quality_stats['sin_marca']/quality_stats['total_productos']*100:.1f}%")
        
        if quality_issues:
            self.warnings.extend(quality_issues)
            print(f"âš ï¸ PROBLEMAS DE CALIDAD DETECTADOS:")
            for issue in quality_issues:
                print(f"   â€¢ {issue}")
        
        self.stats.update(dict(quality_stats))
    
    def generate_comprehensive_report(self):
        """ğŸ“‹ 8. Generar reporte comprehensivo final"""
        print("\n" + "ğŸ“‹" + "="*70 + "ğŸ“‹")
        print("ğŸ“‹ REPORTE COMPREHENSIVO FINAL DE AUDITORÃA")
        print("ğŸ“‹" + "="*70 + "ğŸ“‹")
        
        # EstadÃ­sticas generales
        self.cursor.execute("SELECT COUNT(*) as total FROM master_productos")
        total_products = self.cursor.fetchone()['total']
        
        self.cursor.execute("SELECT COUNT(*) as total FROM master_precios")
        total_prices = self.cursor.fetchone()['total']
        
        print(f"ğŸ“Š ESTADÃSTICAS GENERALES:")
        print(f"   ğŸ“¦ Total productos: {total_products:,}")
        print(f"   ğŸ’° Total registros precios: {total_prices:,}")
        print(f"   ğŸ“… Fecha auditorÃ­a: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
        
        # Resumen de violaciones crÃ­ticas
        if self.critical_violations:
            print(f"\nâŒ VIOLACIONES CRÃTICAS ({len(self.critical_violations)}):")
            for i, violation in enumerate(self.critical_violations, 1):
                print(f"   {i}. {violation}")
        else:
            print(f"\nâœ… NO SE ENCONTRARON VIOLACIONES CRÃTICAS")
        
        # Resumen de advertencias
        if self.warnings:
            print(f"\nâš ï¸ ADVERTENCIAS Y RECOMENDACIONES ({len(self.warnings)}):")
            for i, warning in enumerate(self.warnings, 1):
                print(f"   {i}. {warning}")
        
        # Grupos de duplicados encontrados
        if self.duplicate_groups:
            print(f"\nğŸ” GRUPOS DE DUPLICADOS ENCONTRADOS: {len(self.duplicate_groups)}")
            total_duplicated_products = sum(len(group) for group in self.duplicate_groups)
            print(f"   ğŸ“¦ Total productos involucrados: {total_duplicated_products}")
        
        # Recomendaciones de mejora
        print(f"\nğŸ’¡ RECOMENDACIONES DE MEJORA:")
        
        recommendations = [
            "1. ğŸš« Implementar constraint UNIQUE (codigo_interno, fecha) en master_precios",
            "2. ğŸ”— Agregar constraint UNIQUE en campo link si debe ser Ãºnico",
            "3. ğŸ” Implementar proceso de deduplicaciÃ³n basado en similitud de nombres",
            "4. ğŸ›¡ï¸ Agregar validaciones de precios a nivel de aplicaciÃ³n",
            "5. ğŸ¯ Mejorar proceso de normalizaciÃ³n de datos de entrada",
            "6. ğŸ“Š Configurar monitoreo automÃ¡tico de calidad de datos",
            "7. ğŸ”„ Implementar proceso periÃ³dico de limpieza de duplicados",
            "8. ğŸ“ˆ Crear dashboard de mÃ©tricas de integridad de datos"
        ]
        
        for rec in recommendations:
            print(f"   {rec}")
        
        # Generar archivo de reporte
        report_data = {
            'audit_date': datetime.now().isoformat(),
            'total_products': total_products,
            'total_prices': total_prices,
            'critical_violations': self.critical_violations,
            'warnings': self.warnings,
            'duplicate_groups_count': len(self.duplicate_groups),
            'stats': self.stats,
            'recommendations': recommendations
        }
        
        report_file = f"database_integrity_audit_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nğŸ’¾ REPORTE GUARDADO: {report_file}")
        
        # Resumen final
        status = "ğŸš¨ REQUIERE ATENCIÃ“N" if self.critical_violations else "âœ… SALUDABLE"
        print(f"\nğŸ¯ ESTADO GENERAL DE LA BASE DE DATOS: {status}")
        
        return report_file
    
    def run_complete_audit(self):
        """ğŸš€ Ejecutar auditorÃ­a completa"""
        print("ğŸš€" + "="*70 + "ğŸš€")
        print("ğŸ” INICIANDO AUDITORÃA COMPLETA DE INTEGRIDAD DE BASE DE DATOS")
        print("ğŸš€" + "="*70 + "ğŸš€")
        
        audit_steps = [
            ("ğŸ” CÃ³digos Internos", self.check_duplicate_by_codigo_interno),
            ("ğŸ”— Links/URLs", self.check_duplicate_by_link),
            ("ğŸ“ Similitud de Nombres", self.check_duplicate_by_name_similarity),
            ("ğŸ”§ Especificaciones", self.check_duplicate_by_specs),
            ("ğŸª Entre Retailers", self.check_cross_retailer_duplicates),
            ("ğŸ’° Consistencia Precios", self.analyze_price_consistency),
            ("ğŸ¯ Calidad de Datos", self.analyze_data_quality),
            ("ğŸ“‹ Reporte Final", self.generate_comprehensive_report)
        ]
        
        for step_name, step_func in audit_steps:
            try:
                print(f"\nâ³ Ejecutando: {step_name}...")
                result = step_func()
                if result:
                    print(f"âœ… {step_name} completado")
            except Exception as e:
                print(f"âŒ Error en {step_name}: {e}")
                import traceback
                print(f"ğŸ” Detalle: {traceback.format_exc()}")
        
        print("\nğŸ‰ AUDITORÃA COMPLETA FINALIZADA")
    
    def close(self):
        """ğŸ”š Cerrar conexiones"""
        if self.cursor:
            self.cursor.close()
        if self.conn:
            self.conn.close()
        print("ğŸ”š Conexiones cerradas")

def main():
    """ğŸš€ FunciÃ³n principal"""
    print("ğŸ” Iniciando AuditorÃ­a Avanzada de Integridad...")
    
    auditor = AdvancedDatabaseIntegrityAuditor()
    
    try:
        auditor.run_complete_audit()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ AuditorÃ­a interrumpida por el usuario")
    except Exception as e:
        print(f"\nâŒ Error crÃ­tico durante auditorÃ­a: {e}")
        import traceback
        traceback.print_exc()
    finally:
        auditor.close()

if __name__ == "__main__":
    main()