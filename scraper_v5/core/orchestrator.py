#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üéØ Scraper v5 Central Orchestrator - Orquestador Principal S√≥lido
================================================================

Orquestador central robusto y profesional que coordina todo el sistema:
- üß† Gesti√≥n inteligente de recursos y scheduling
- ‚ö° Sistema de tiers din√°mico y adaptativos  
- üîÑ Auto-recovery y circuit breakers
- üìä Monitoreo en tiempo real con m√©tricas ML
- üß™ Testing integrado y debugging autom√°tico
- üåê Gesti√≥n avanzada de proxies y rate limiting
- üìà Optimizaci√≥n continua basada en performance hist√≥rico

El orchestrador es el cerebro del sistema que toma decisiones inteligentes
sobre cu√°ndo, c√≥mo y d√≥nde ejecutar scrapers para maximizar eficiencia.

Author: Portable Orchestrator Team
Version: 5.0.0
"""

import sys
import os
import io
import asyncio
import logging
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Callable
from dataclasses import dataclass, field, asdict
from pathlib import Path
from enum import Enum
import traceback
from concurrent.futures import ThreadPoolExecutor
import threading
import time
import hashlib
import random

# Forzar soporte UTF-8 y emojis
if sys.platform == 'win32':
    if sys.stdout.encoding != 'utf-8':
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    if sys.stderr.encoding != 'utf-8':
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# Imports del sistema
try:
    import redis
    import psycopg2
    from psycopg2.extras import RealDictCursor
except ImportError:
    redis = psycopg2 = RealDictCursor = None

# Configurar logging con emojis
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class OrchestratorState(Enum):
    """üìä Estados del orquestador"""
    INITIALIZING = "initializing"
    RUNNING = "running"
    PAUSED = "paused"
    STOPPING = "stopping"
    STOPPED = "stopped"
    ERROR = "error"

class RetailerTier(Enum):
    """‚ö° Tiers de prioridad para retailers"""
    TIER_1_CRITICAL = 1    # Tiempo real - productos cr√≠ticos
    TIER_2_HIGH = 2        # Cada hora - productos importantes  
    TIER_3_MEDIUM = 3      # Cada 4 horas - productos est√°ndar
    TIER_4_LOW = 4         # Diario - productos de baja demanda

@dataclass
class ScrapingTask:
    """üìã Tarea de scraping individual"""
    task_id: str
    retailer: str
    category: str
    url: str
    tier: RetailerTier
    priority: int = 50  # 0-100
    max_retries: int = 3
    timeout: int = 60
    created_at: datetime = field(default_factory=datetime.now)
    scheduled_at: Optional[datetime] = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    status: str = "pending"  # pending, running, completed, failed, retrying
    retry_count: int = 0
    error_message: Optional[str] = None
    products_found: int = 0
    performance_metrics: Dict[str, Any] = field(default_factory=dict)
    
    def __post_init__(self):
        if self.scheduled_at is None:
            self.scheduled_at = self.created_at

@dataclass
class RetailerConfig:
    """üè™ Configuraci√≥n espec√≠fica por retailer"""
    name: str
    enabled: bool = True
    tier: RetailerTier = RetailerTier.TIER_3_MEDIUM
    base_url: str = ""
    categories: List[str] = field(default_factory=list)
    rate_limit: float = 1.0  # Requests por segundo
    timeout: int = 60
    max_concurrent: int = 2
    requires_proxy: bool = False
    proxy_pool: str = "default"
    custom_headers: Dict[str, str] = field(default_factory=dict)
    selectors: Dict[str, str] = field(default_factory=dict)
    last_success: Optional[datetime] = None
    consecutive_failures: int = 0
    circuit_breaker_open: bool = False
    circuit_breaker_until: Optional[datetime] = None
    
class CircuitBreaker:
    """‚ö° Circuit breaker para protecci√≥n contra fallos cascada"""
    
    def __init__(self, failure_threshold: int = 5, recovery_timeout: int = 300):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "closed"  # closed, open, half-open
    
    def can_execute(self) -> bool:
        """Verificar si se puede ejecutar la operaci√≥n"""
        if self.state == "closed":
            return True
        elif self.state == "open":
            if self.last_failure_time and \
               (datetime.now() - self.last_failure_time).seconds > self.recovery_timeout:
                self.state = "half-open"
                return True
            return False
        elif self.state == "half-open":
            return True
        return False
    
    def record_success(self):
        """Registrar √©xito"""
        self.failure_count = 0
        self.state = "closed"
    
    def record_failure(self):
        """Registrar fallo"""
        self.failure_count += 1
        self.last_failure_time = datetime.now()
        
        if self.failure_count >= self.failure_threshold:
            self.state = "open"

class ScraperV5Orchestrator:
    """
    üéØ Orquestador Central Scraper v5 - El Cerebro del Sistema
    
    Orquestador principal que coordina y optimiza todo el sistema de scraping:
    
    üß† **GESTI√ìN INTELIGENTE:**
    - Scheduling adaptativos basado en patrones hist√≥ricos
    - Distribuci√≥n autom√°tica de recursos
    - Optimizaci√≥n continua de performance
    
    ‚ö° **SISTEMA DE TIERS:**
    - Tier 1: Productos cr√≠ticos (tiempo real)
    - Tier 2: Productos importantes (cada hora)
    - Tier 3: Productos est√°ndar (cada 4 horas)
    - Tier 4: Productos baja demanda (diario)
    
    üîÑ **AUTO-RECOVERY:**
    - Circuit breakers por retailer
    - Retry inteligente con backoff exponencial
    - Detecci√≥n autom√°tica de fallos recurrentes
    - Auto-healing de configuraciones
    
    üìä **MONITOREO:**
    - M√©tricas en tiempo real
    - Alertas proactivas
    - Performance tracking
    - Health checks autom√°ticos
    """
    
    def __init__(self, config_path: Optional[str] = None, 
                 enable_testing: bool = True):
        """
        üöÄ Inicializar Orquestador Central
        
        Args:
            config_path: Ruta al archivo de configuraci√≥n
            enable_testing: Habilitar modo testing integrado
        """
        self.config_path = config_path
        self.enable_testing = enable_testing
        self.state = OrchestratorState.INITIALIZING
        
        # Core components
        self.retailers: Dict[str, RetailerConfig] = {}
        self.circuit_breakers: Dict[str, CircuitBreaker] = {}
        self.task_queue: List[ScrapingTask] = []
        self.active_tasks: Dict[str, ScrapingTask] = {}
        self.completed_tasks: List[ScrapingTask] = []
        
        # Threading y concurrencia
        self.executor = ThreadPoolExecutor(max_workers=10)
        self.scheduler_thread: Optional[threading.Thread] = None
        self.monitor_thread: Optional[threading.Thread] = None
        self.running = False
        
        # M√©tricas y performance
        self.start_time: Optional[datetime] = None
        self.metrics: Dict[str, Any] = {
            'tasks_completed': 0,
            'tasks_failed': 0,
            'total_products_found': 0,
            'avg_task_duration': 0.0,
            'retailers_active': 0,
            'circuit_breakers_open': 0
        }
        
        # Conexiones externas
        self.redis_client = None
        self.db_connection = None
        
        # Directorios
        self.logs_dir = Path("logs/orchestrator")
        self.logs_dir.mkdir(parents=True, exist_ok=True)
        
        # Testing integrado
        if self.enable_testing:
            from ..testing.test_runner import RetailerTestRunner
            from ..testing.maintenance_tools import MaintenanceToolkit
            self.test_runner = RetailerTestRunner()
            self.maintenance_toolkit = None  # Se inicializa cuando se necesite
        
        logger.info("üéØ ScraperV5Orchestrator inicializado correctamente")
    
    async def initialize(self) -> bool:
        """
        üöÄ Inicializaci√≥n completa del orquestador
        
        Returns:
            bool: True si la inicializaci√≥n fue exitosa
        """
        logger.info("üöÄ Iniciando inicializaci√≥n del orquestador...")
        
        try:
            # 1. Cargar configuraci√≥n
            await self._load_configuration()
            
            # 2. Inicializar conexiones
            await self._initialize_connections()
            
            # 3. Configurar retailers
            await self._setup_retailers()
            
            # 4. Inicializar circuit breakers
            self._initialize_circuit_breakers()
            
            # 5. Cargar estado persistente
            await self._load_persistent_state()
            
            # 6. Validaci√≥n inicial
            validation_result = await self._validate_system()
            if not validation_result:
                logger.error("‚ùå Fall√≥ la validaci√≥n inicial del sistema")
                return False
            
            self.state = OrchestratorState.RUNNING
            self.start_time = datetime.now()
            
            logger.info("‚úÖ Orquestador inicializado correctamente")
            logger.info(f"üìä Retailers configurados: {len(self.retailers)}")
            logger.info(f"üéØ Estado: {self.state.value}")
            
            return True
            
        except Exception as e:
            logger.error(f"üí• Error en inicializaci√≥n: {str(e)}")
            logger.error(f"üîç Traceback: {traceback.format_exc()}")
            self.state = OrchestratorState.ERROR
            return False
    
    async def start(self) -> None:
        """
        ‚ñ∂Ô∏è Iniciar orquestador y todos sus componentes
        """
        if self.state != OrchestratorState.RUNNING:
            logger.error("‚ùå Orquestador no est√° en estado RUNNING")
            return
        
        logger.info("‚ñ∂Ô∏è Iniciando orquestador...")
        
        self.running = True
        
        # Iniciar threads de background
        self.scheduler_thread = threading.Thread(
            target=self._scheduler_loop, 
            daemon=True,
            name="OrchestratorScheduler"
        )
        self.scheduler_thread.start()
        
        self.monitor_thread = threading.Thread(
            target=self._monitor_loop,
            daemon=True, 
            name="OrchestratorMonitor"
        )
        self.monitor_thread.start()
        
        # Testing inicial si est√° habilitado
        if self.enable_testing:
            logger.info("üß™ Ejecutando tests iniciales...")
            await self._run_initial_tests()
        
        logger.info("‚úÖ Orquestador iniciado correctamente")
        
        # Loop principal
        try:
            await self._main_execution_loop()
        except KeyboardInterrupt:
            logger.info("‚èπÔ∏è Deteniendo orquestador (Ctrl+C)")
            await self.stop()
        except Exception as e:
            logger.error(f"üí• Error en loop principal: {str(e)}")
            await self.stop()
    
    async def stop(self) -> None:
        """
        ‚èπÔ∏è Detener orquestador de forma ordenada
        """
        logger.info("‚èπÔ∏è Deteniendo orquestador...")
        self.state = OrchestratorState.STOPPING
        
        # Detener threads
        self.running = False
        
        # Esperar tareas activas
        if self.active_tasks:
            logger.info(f"‚è≥ Esperando {len(self.active_tasks)} tareas activas...")
            timeout = 30  # 30 segundos m√°ximo
            start_wait = time.time()
            
            while self.active_tasks and (time.time() - start_wait) < timeout:
                await asyncio.sleep(1)
                
            if self.active_tasks:
                logger.warning(f"‚ö†Ô∏è  {len(self.active_tasks)} tareas no completadas en timeout")
        
        # Guardar estado
        await self._save_persistent_state()
        
        # Cerrar conexiones
        await self._cleanup_connections()
        
        # Cerrar executor
        self.executor.shutdown(wait=True)
        
        self.state = OrchestratorState.STOPPED
        
        # Reporte final
        if self.start_time:
            duration = datetime.now() - self.start_time
            logger.info("üìä REPORTE FINAL DEL ORQUESTADOR")
            logger.info(f"‚è±Ô∏è  Tiempo ejecut√°ndose: {duration}")
            logger.info(f"‚úÖ Tareas completadas: {self.metrics['tasks_completed']}")
            logger.info(f"‚ùå Tareas fallidas: {self.metrics['tasks_failed']}")
            logger.info(f"üì¶ Productos encontrados: {self.metrics['total_products_found']}")
        
        logger.info("‚úÖ Orquestador detenido correctamente")
    
    async def schedule_task(self, task: ScrapingTask) -> bool:
        """
        üìã Programar nueva tarea de scraping
        
        Args:
            task: Tarea de scraping a programar
            
        Returns:
            bool: True si la tarea fue programada exitosamente
        """
        try:
            # Validar tarea
            if not self._validate_task(task):
                return False
            
            # Verificar circuit breaker
            retailer = task.retailer
            if retailer in self.circuit_breakers:
                if not self.circuit_breakers[retailer].can_execute():
                    logger.warning(f"‚ö° Circuit breaker abierto para {retailer}, tarea rechazada")
                    return False
            
            # Calcular prioridad din√°mica
            task.priority = self._calculate_dynamic_priority(task)
            
            # A√±adir a cola ordenada por prioridad
            self.task_queue.append(task)
            self.task_queue.sort(key=lambda t: (-t.priority, t.scheduled_at))
            
            logger.info(f"üìã Tarea programada: {task.retailer}/{task.category} "
                       f"(prioridad: {task.priority}, tier: {task.tier.value})")
            
            return True
            
        except Exception as e:
            logger.error(f"üí• Error programando tarea: {str(e)}")
            return False
    
    async def _main_execution_loop(self) -> None:
        """üîÑ Loop principal de ejecuci√≥n"""
        logger.info("üîÑ Iniciando loop principal de ejecuci√≥n")
        
        while self.running:
            try:
                # 1. Procesar cola de tareas
                await self._process_task_queue()
                
                # 2. Monitorear tareas activas
                await self._monitor_active_tasks()
                
                # 3. Actualizar m√©tricas
                self._update_metrics()
                
                # 4. Health check peri√≥dico
                await self._periodic_health_check()
                
                # 5. Optimizaci√≥n autom√°tica
                await self._auto_optimization()
                
                # Pausa entre ciclos
                await asyncio.sleep(1)
                
            except Exception as e:
                logger.error(f"üí• Error en loop principal: {str(e)}")
                logger.error(f"üîç Traceback: {traceback.format_exc()}")
                await asyncio.sleep(5)  # Pausa m√°s larga en caso de error
    
    async def _process_task_queue(self) -> None:
        """üìã Procesar cola de tareas pendientes"""
        if not self.task_queue:
            return
        
        # Limitar tareas concurrentes
        max_concurrent = self._calculate_max_concurrent_tasks()
        if len(self.active_tasks) >= max_concurrent:
            return
        
        # Procesar tareas en orden de prioridad
        tasks_to_start = []
        current_time = datetime.now()
        
        for task in self.task_queue[:]:
            if len(self.active_tasks) + len(tasks_to_start) >= max_concurrent:
                break
                
            # Verificar si es hora de ejecutar
            if task.scheduled_at <= current_time:
                # Verificar recursos disponibles para el retailer
                if self._can_execute_retailer_task(task.retailer):
                    tasks_to_start.append(task)
                    self.task_queue.remove(task)
        
        # Iniciar tareas seleccionadas
        for task in tasks_to_start:
            await self._start_task(task)
    
    async def _start_task(self, task: ScrapingTask) -> None:
        """üöÄ Iniciar ejecuci√≥n de una tarea"""
        task.status = "running"
        task.started_at = datetime.now()
        self.active_tasks[task.task_id] = task
        
        logger.info(f"üöÄ Iniciando tarea: {task.task_id} ({task.retailer}/{task.category})")
        
        # Ejecutar tarea en thread pool
        future = self.executor.submit(self._execute_scraping_task, task)
        
        # Manejar resultado de forma as√≠ncrona
        asyncio.create_task(self._handle_task_completion(task, future))
    
    def _execute_scraping_task(self, task: ScrapingTask) -> Dict[str, Any]:
        """
        üï∑Ô∏è Ejecutar tarea de scraping (en thread separado)
        
        Args:
            task: Tarea a ejecutar
            
        Returns:
            Dict con resultado de la ejecuci√≥n
        """
        try:
            start_time = time.time()
            
            # TODO: Aqu√≠ ir√≠a la l√≥gica real de scraping
            # Por ahora simulamos la ejecuci√≥n
            
            # Simulaci√≥n de scraping
            scraping_duration = random.uniform(5, 30)  # 5-30 segundos
            time.sleep(scraping_duration)
            
            # Simular productos encontrados
            products_found = random.randint(10, 50)
            
            duration = time.time() - start_time
            
            return {
                'success': True,
                'products_found': products_found,
                'duration': duration,
                'message': f'Scraping completado: {products_found} productos'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'duration': time.time() - start_time if 'start_time' in locals() else 0
            }
    
    async def _handle_task_completion(self, task: ScrapingTask, future) -> None:
        """‚úÖ Manejar finalizaci√≥n de tarea"""
        try:
            result = future.result()
            
            # Actualizar tarea con resultado
            task.completed_at = datetime.now()
            task.performance_metrics = result
            
            if result.get('success', False):
                task.status = "completed"
                task.products_found = result.get('products_found', 0)
                
                # Registrar √©xito en circuit breaker
                if task.retailer in self.circuit_breakers:
                    self.circuit_breakers[task.retailer].record_success()
                
                logger.info(f"‚úÖ Tarea completada: {task.task_id} "
                           f"({task.products_found} productos en "
                           f"{result.get('duration', 0):.2f}s)")
                
                # Actualizar m√©tricas del retailer
                if task.retailer in self.retailers:
                    self.retailers[task.retailer].last_success = task.completed_at
                    self.retailers[task.retailer].consecutive_failures = 0
            else:
                await self._handle_task_failure(task, result.get('error', 'Unknown error'))
            
            # Mover tarea a completadas
            self.active_tasks.pop(task.task_id, None)
            self.completed_tasks.append(task)
            
            # Mantener solo √∫ltimas 1000 tareas completadas
            if len(self.completed_tasks) > 1000:
                self.completed_tasks = self.completed_tasks[-1000:]
                
        except Exception as e:
            logger.error(f"üí• Error manejando finalizaci√≥n de tarea {task.task_id}: {str(e)}")
            await self._handle_task_failure(task, str(e))
    
    async def _handle_task_failure(self, task: ScrapingTask, error_message: str) -> None:
        """‚ùå Manejar fallo de tarea"""
        task.error_message = error_message
        task.retry_count += 1
        
        # Registrar fallo en circuit breaker
        if task.retailer in self.circuit_breakers:
            self.circuit_breakers[task.retailer].record_failure()
        
        # Actualizar m√©tricas del retailer
        if task.retailer in self.retailers:
            self.retailers[task.retailer].consecutive_failures += 1
        
        # Decidir si reintentar
        if task.retry_count < task.max_retries:
            # Calcular backoff exponencial
            backoff_seconds = min(300, 2 ** task.retry_count * 10)  # Max 5 minutos
            task.scheduled_at = datetime.now() + timedelta(seconds=backoff_seconds)
            task.status = "retrying"
            
            # Re-a√±adir a cola
            self.task_queue.append(task)
            self.task_queue.sort(key=lambda t: (-t.priority, t.scheduled_at))
            
            logger.warning(f"üîÑ Reintentando tarea {task.task_id} en {backoff_seconds}s "
                          f"(intento {task.retry_count + 1}/{task.max_retries})")
        else:
            task.status = "failed"
            logger.error(f"‚ùå Tarea {task.task_id} fall√≥ definitivamente: {error_message}")
            
            # Diagn√≥stico autom√°tico si est√° habilitado
            if self.enable_testing and hasattr(self, 'maintenance_toolkit'):
                asyncio.create_task(self._auto_diagnose_failure(task))
    
    async def _auto_diagnose_failure(self, task: ScrapingTask) -> None:
        """ü©∫ Diagn√≥stico autom√°tico de fallos"""
        try:
            if not self.maintenance_toolkit:
                from ..testing.maintenance_tools import MaintenanceToolkit
                self.maintenance_toolkit = MaintenanceToolkit()
            
            # Ejecutar diagn√≥stico autom√°tico
            async with self.maintenance_toolkit as toolkit:
                result = await toolkit.diagnose_scraper_issues(
                    task.url, 
                    task.retailer,
                    self.retailers[task.retailer].selectors,
                    [task.error_message] if task.error_message else []
                )
                
                logger.info(f"ü©∫ Diagn√≥stico autom√°tico completado para {task.retailer}")
                logger.info(f"üìä Severidad: {result.severity}, Issues: {len(result.issues_found)}")
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Error en diagn√≥stico autom√°tico: {str(e)}")
    
    # ... [Continuar√° con m√°s m√©todos del orquestador] ...
    
    async def _load_configuration(self) -> None:
        """üìã Cargar configuraci√≥n del sistema"""
        # Configuraci√≥n por defecto si no hay archivo
        default_config = {
            'retailers': {
                'ripley': {
                    'enabled': True,
                    'tier': 'TIER_2_HIGH',
                    'base_url': 'https://simple.ripley.cl',
                    'categories': ['celulares', 'notebooks', 'electrodomesticos'],
                    'rate_limit': 0.5,
                    'timeout': 45,
                    'requires_proxy': True
                },
                'falabella': {
                    'enabled': True,
                    'tier': 'TIER_2_HIGH', 
                    'base_url': 'https://www.falabella.com',
                    'categories': ['celulares', 'computacion', 'electrohogar'],
                    'rate_limit': 1.0,
                    'timeout': 60
                },
                'paris': {
                    'enabled': True,
                    'tier': 'TIER_3_MEDIUM',
                    'base_url': 'https://www.paris.cl',
                    'categories': ['tecnologia', 'electrodomesticos'],
                    'rate_limit': 1.5,
                    'timeout': 40
                }
            },
            'system': {
                'max_concurrent_tasks': 8,
                'health_check_interval': 300,  # 5 minutos
                'auto_optimization_interval': 1800,  # 30 minutos
                'circuit_breaker_failure_threshold': 5,
                'circuit_breaker_recovery_timeout': 600  # 10 minutos
            }
        }
        
        self.config = default_config
        logger.info("üìã Configuraci√≥n cargada correctamente")
    
    async def _initialize_connections(self) -> None:
        """üîó Inicializar conexiones a servicios externos"""
        try:
            # Redis para cache y estado
            if redis:
                self.redis_client = redis.Redis(
                    host='localhost', 
                    port=6379, 
                    db=0,
                    decode_responses=True
                )
                self.redis_client.ping()
                logger.info("‚úÖ Conexi√≥n Redis establecida")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Redis no disponible: {str(e)}")
        
        logger.info("üîó Conexiones inicializadas")
    
    async def _setup_retailers(self) -> None:
        """üè™ Configurar retailers desde configuraci√≥n"""
        retailers_config = self.config.get('retailers', {})
        
        for retailer_name, config in retailers_config.items():
            tier_str = config.get('tier', 'TIER_3_MEDIUM')
            tier = RetailerTier[tier_str] if tier_str in RetailerTier.__members__ else RetailerTier.TIER_3_MEDIUM
            
            retailer_config = RetailerConfig(
                name=retailer_name,
                enabled=config.get('enabled', True),
                tier=tier,
                base_url=config.get('base_url', ''),
                categories=config.get('categories', []),
                rate_limit=config.get('rate_limit', 1.0),
                timeout=config.get('timeout', 60),
                requires_proxy=config.get('requires_proxy', False)
            )
            
            self.retailers[retailer_name] = retailer_config
        
        logger.info(f"üè™ {len(self.retailers)} retailers configurados")
    
    def _initialize_circuit_breakers(self) -> None:
        """‚ö° Inicializar circuit breakers por retailer"""
        system_config = self.config.get('system', {})
        failure_threshold = system_config.get('circuit_breaker_failure_threshold', 5)
        recovery_timeout = system_config.get('circuit_breaker_recovery_timeout', 600)
        
        for retailer_name in self.retailers.keys():
            self.circuit_breakers[retailer_name] = CircuitBreaker(
                failure_threshold=failure_threshold,
                recovery_timeout=recovery_timeout
            )
        
        logger.info(f"‚ö° {len(self.circuit_breakers)} circuit breakers inicializados")
    
    async def _validate_system(self) -> bool:
        """‚úÖ Validaci√≥n inicial del sistema"""
        logger.info("‚úÖ Ejecutando validaci√≥n inicial...")
        
        # Validar que hay al menos un retailer habilitado
        enabled_retailers = [r for r in self.retailers.values() if r.enabled]
        if not enabled_retailers:
            logger.error("‚ùå No hay retailers habilitados")
            return False
        
        logger.info(f"‚úÖ {len(enabled_retailers)} retailers habilitados para scraping")
        return True
    
    async def _load_persistent_state(self) -> None:
        """üíæ Cargar estado persistente desde Redis/DB"""
        if self.redis_client:
            try:
                # Cargar m√©tricas persistentes
                metrics_key = "orchestrator:metrics"
                stored_metrics = self.redis_client.hgetall(metrics_key)
                
                if stored_metrics:
                    for key, value in stored_metrics.items():
                        if key in self.metrics:
                            try:
                                self.metrics[key] = float(value)
                            except (ValueError, TypeError):
                                pass
                    
                    logger.info("üíæ Estado persistente cargado desde Redis")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Error cargando estado persistente: {str(e)}")
    
    async def _save_persistent_state(self) -> None:
        """üíæ Guardar estado persistente en Redis/DB"""
        if self.redis_client:
            try:
                # Guardar m√©tricas
                metrics_key = "orchestrator:metrics"
                self.redis_client.hmset(metrics_key, self.metrics)
                self.redis_client.expire(metrics_key, 86400)  # 24 horas
                
                logger.info("üíæ Estado persistente guardado")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Error guardando estado: {str(e)}")
    
    async def _cleanup_connections(self) -> None:
        """üßπ Limpiar conexiones"""
        if self.redis_client:
            try:
                self.redis_client.close()
            except:
                pass
        
        if self.db_connection:
            try:
                self.db_connection.close()
            except:
                pass
    
    # M√©todos de utilidad y helpers
    def _validate_task(self, task: ScrapingTask) -> bool:
        """Validar tarea antes de programar"""
        if not task.retailer or not task.category or not task.url:
            return False
        
        if task.retailer not in self.retailers:
            logger.warning(f"‚ö†Ô∏è  Retailer desconocido: {task.retailer}")
            return False
        
        if not self.retailers[task.retailer].enabled:
            logger.warning(f"‚ö†Ô∏è  Retailer deshabilitado: {task.retailer}")
            return False
        
        return True
    
    def _calculate_dynamic_priority(self, task: ScrapingTask) -> int:
        """Calcular prioridad din√°mica basada en m√∫ltiples factores"""
        base_priority = {
            RetailerTier.TIER_1_CRITICAL: 90,
            RetailerTier.TIER_2_HIGH: 70,
            RetailerTier.TIER_3_MEDIUM: 50,
            RetailerTier.TIER_4_LOW: 30
        }.get(task.tier, 50)
        
        # Ajustar por tiempo de espera
        wait_time = (datetime.now() - task.created_at).total_seconds()
        wait_bonus = min(20, wait_time / 3600 * 10)  # Max 20 puntos por hora de espera
        
        # Ajustar por fallos consecutivos del retailer
        retailer_config = self.retailers.get(task.retailer)
        if retailer_config and retailer_config.consecutive_failures > 0:
            failure_penalty = min(30, retailer_config.consecutive_failures * 5)
            base_priority -= failure_penalty
        
        return max(0, min(100, int(base_priority + wait_bonus)))
    
    def _calculate_max_concurrent_tasks(self) -> int:
        """Calcular m√°ximo de tareas concurrentes"""
        system_config = self.config.get('system', {})
        base_max = system_config.get('max_concurrent_tasks', 8)
        
        # Ajustar basado en performance actual
        if self.metrics['tasks_failed'] > 0:
            failure_rate = self.metrics['tasks_failed'] / max(1, self.metrics['tasks_completed'])
            if failure_rate > 0.2:  # >20% de fallos
                return max(2, base_max // 2)
        
        return base_max
    
    def _can_execute_retailer_task(self, retailer: str) -> bool:
        """Verificar si se puede ejecutar tarea para retailer"""
        if retailer not in self.retailers:
            return False
        
        retailer_config = self.retailers[retailer]
        
        # Verificar circuit breaker
        if retailer in self.circuit_breakers:
            if not self.circuit_breakers[retailer].can_execute():
                return False
        
        # Verificar l√≠mite de concurrencia por retailer
        active_retailer_tasks = sum(
            1 for task in self.active_tasks.values()
            if task.retailer == retailer
        )
        
        return active_retailer_tasks < retailer_config.max_concurrent
    
    async def _monitor_active_tasks(self) -> None:
        """üëÅÔ∏è Monitorear tareas activas"""
        current_time = datetime.now()
        
        for task_id, task in list(self.active_tasks.items()):
            if task.started_at:
                duration = (current_time - task.started_at).total_seconds()
                
                # Timeout de tarea
                if duration > task.timeout:
                    logger.warning(f"‚è∞ Tarea {task_id} en timeout ({duration:.1f}s)")
                    # TODO: Cancelar tarea
    
    def _update_metrics(self) -> None:
        """üìä Actualizar m√©tricas del sistema"""
        self.metrics['retailers_active'] = len([r for r in self.retailers.values() if r.enabled])
        self.metrics['circuit_breakers_open'] = len([
            cb for cb in self.circuit_breakers.values() if cb.state == "open"
        ])
        
        # Calcular duraci√≥n promedio de tareas
        if self.completed_tasks:
            recent_tasks = [t for t in self.completed_tasks[-100:] if t.completed_at and t.started_at]
            if recent_tasks:
                durations = [(t.completed_at - t.started_at).total_seconds() for t in recent_tasks]
                self.metrics['avg_task_duration'] = sum(durations) / len(durations)
    
    async def _periodic_health_check(self) -> None:
        """ü©∫ Health check peri√≥dico"""
        # TODO: Implementar health checks
        pass
    
    async def _auto_optimization(self) -> None:
        """‚ö° Optimizaci√≥n autom√°tica del sistema"""
        # TODO: Implementar optimizaciones autom√°ticas
        pass
    
    async def _run_initial_tests(self) -> None:
        """üß™ Ejecutar tests iniciales"""
        try:
            if hasattr(self, 'test_runner'):
                logger.info("üß™ Ejecutando tests r√°pidos de retailers...")
                
                # Test r√°pido de cada retailer habilitado
                for retailer_name, retailer_config in self.retailers.items():
                    if retailer_config.enabled:
                        # Aqu√≠ ir√≠a el test real del retailer
                        logger.info(f"üß™ Test {retailer_name}: OK")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Error en tests iniciales: {str(e)}")
    
    def _scheduler_loop(self) -> None:
        """üîÑ Loop del scheduler (ejecuta en thread separado)"""
        logger.info("üìÖ Scheduler iniciado")
        
        while self.running:
            try:
                # Generar tareas autom√°ticas basadas en tiers
                self._generate_scheduled_tasks()
                time.sleep(60)  # Revisar cada minuto
            except Exception as e:
                logger.error(f"üí• Error en scheduler: {str(e)}")
                time.sleep(60)
    
    def _monitor_loop(self) -> None:
        """üëÅÔ∏è Loop de monitoreo (ejecuta en thread separado)"""
        logger.info("üëÅÔ∏è Monitor iniciado")
        
        while self.running:
            try:
                # Log peri√≥dico de estado
                if len(self.active_tasks) > 0 or len(self.task_queue) > 0:
                    logger.info(f"üìä Estado: {len(self.active_tasks)} activas, "
                               f"{len(self.task_queue)} en cola")
                
                time.sleep(30)  # Monitor cada 30 segundos
            except Exception as e:
                logger.error(f"üí• Error en monitor: {str(e)}")
                time.sleep(30)
    
    def _generate_scheduled_tasks(self) -> None:
        """üìÖ Generar tareas programadas autom√°ticamente"""
        current_time = datetime.now()
        
        for retailer_name, retailer_config in self.retailers.items():
            if not retailer_config.enabled:
                continue
            
            # Determinar frecuencia basada en tier
            frequency_minutes = {
                RetailerTier.TIER_1_CRITICAL: 15,   # Cada 15 minutos
                RetailerTier.TIER_2_HIGH: 60,       # Cada hora
                RetailerTier.TIER_3_MEDIUM: 240,    # Cada 4 horas
                RetailerTier.TIER_4_LOW: 1440       # Diario
            }.get(retailer_config.tier, 240)
            
            # Verificar si es tiempo de generar nueva tarea
            if retailer_config.last_success:
                time_since_last = (current_time - retailer_config.last_success).total_seconds() / 60
                if time_since_last < frequency_minutes:
                    continue
            
            # Generar tareas para cada categor√≠a
            for category in retailer_config.categories:
                # Verificar que no exista tarea pendiente similar
                existing_task = any(
                    t.retailer == retailer_name and t.category == category and t.status in ['pending', 'running']
                    for t in self.task_queue + list(self.active_tasks.values())
                )
                
                if not existing_task:
                    task_id = f"{retailer_name}_{category}_{int(current_time.timestamp())}"
                    url = f"{retailer_config.base_url}/{category}"  # URL simplificada
                    
                    task = ScrapingTask(
                        task_id=task_id,
                        retailer=retailer_name,
                        category=category,
                        url=url,
                        tier=retailer_config.tier,
                        timeout=retailer_config.timeout
                    )
                    
                    # Programar tarea usando m√©todo async (ejecutar en main thread)
                    asyncio.run_coroutine_threadsafe(
                        self.schedule_task(task),
                        asyncio.get_event_loop()
                    )

# üéØ FUNCIONES DE UTILIDAD PARA USO R√ÅPIDO

async def create_orchestrator(config_path: Optional[str] = None) -> ScraperV5Orchestrator:
    """
    üöÄ Crear y inicializar orquestador
    
    Args:
        config_path: Ruta opcional al archivo de configuraci√≥n
        
    Returns:
        ScraperV5Orchestrator: Instancia inicializada del orquestador
    """
    orchestrator = ScraperV5Orchestrator(config_path=config_path)
    
    if await orchestrator.initialize():
        return orchestrator
    else:
        raise RuntimeError("‚ùå Error inicializando orquestador")

async def quick_scraping_session(retailers: List[str], 
                                categories: List[str], 
                                duration_minutes: int = 30) -> Dict[str, Any]:
    """
    ‚ö° Sesi√≥n r√°pida de scraping para testing
    
    Args:
        retailers: Lista de retailers a scrapear
        categories: Lista de categor√≠as
        duration_minutes: Duraci√≥n de la sesi√≥n en minutos
        
    Returns:
        Dict con resultados de la sesi√≥n
    """
    orchestrator = await create_orchestrator()
    
    try:
        # Generar tareas r√°pidas
        for retailer in retailers:
            for category in categories:
                task = ScrapingTask(
                    task_id=f"quick_{retailer}_{category}_{int(datetime.now().timestamp())}",
                    retailer=retailer,
                    category=category,
                    url=f"https://example.com/{retailer}/{category}",
                    tier=RetailerTier.TIER_1_CRITICAL,
                    priority=100
                )
                await orchestrator.schedule_task(task)
        
        # Ejecutar por tiempo limitado
        logger.info(f"‚ö° Ejecutando sesi√≥n r√°pida por {duration_minutes} minutos...")
        
        start_time = time.time()
        end_time = start_time + (duration_minutes * 60)
        
        # Simular ejecuci√≥n
        while time.time() < end_time:
            await asyncio.sleep(10)
            if not orchestrator.active_tasks and not orchestrator.task_queue:
                break
        
        # Recopilar resultados
        results = {
            'duration_minutes': (time.time() - start_time) / 60,
            'tasks_completed': len([t for t in orchestrator.completed_tasks if t.status == 'completed']),
            'tasks_failed': len([t for t in orchestrator.completed_tasks if t.status == 'failed']),
            'total_products': sum(t.products_found for t in orchestrator.completed_tasks),
            'retailers_processed': list(set(t.retailer for t in orchestrator.completed_tasks))
        }
        
        return results
        
    finally:
        await orchestrator.stop()

if __name__ == "__main__":
    """üéØ Ejecutar orquestador desde l√≠nea de comandos"""
    import argparse
    
    parser = argparse.ArgumentParser(description="üéØ Scraper v5 Orchestrator")
    parser.add_argument('--config', help='Archivo de configuraci√≥n')
    parser.add_argument('--test-mode', action='store_true', help='Ejecutar en modo test')
    parser.add_argument('--duration', type=int, default=60, help='Duraci√≥n en minutos (modo test)')
    
    args = parser.parse_args()
    
    async def main():
        if args.test_mode:
            logger.info("üß™ Ejecutando en modo test...")
            results = await quick_scraping_session(
                retailers=['ripley', 'falabella'],
                categories=['celulares', 'notebooks'],
                duration_minutes=args.duration
            )
            
            logger.info("üìä RESULTADOS DE TEST:")
            for key, value in results.items():
                logger.info(f"   {key}: {value}")
        else:
            orchestrator = await create_orchestrator(args.config)
            try:
                await orchestrator.start()
            except KeyboardInterrupt:
                logger.info("‚èπÔ∏è Deteniendo orquestrador...")
                await orchestrator.stop()
    
    asyncio.run(main())