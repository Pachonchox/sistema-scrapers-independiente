# üì¶ Sistema de Respaldo Parquet

## üéØ Objetivo

Sistema de respaldo autom√°tico que guarda **datos crudos** de los scrapers en archivos Parquet organizados por retailer y fecha, proporcionando un respaldo completo y eficiente para an√°lisis posterior.

## üèóÔ∏è Arquitectura del Sistema

### **Flujo de Respaldo Integrado**

```mermaid
graph TD
    A[üï∑Ô∏è Scraper V5] --> B[üìä Extracci√≥n Productos]
    B --> C[üíæ Guardar en PostgreSQL]
    B --> D[üì¶ Respaldo Parquet]
    
    D --> E[üóÇÔ∏è Organizaci√≥n por Retailer/Fecha]
    E --> F[üìã Metadata JSON]
    E --> G[üóúÔ∏è Compresi√≥n Snappy]
    
    G --> H[üìÅ Archivo Final]
    H --> I[üìä Estad√≠sticas]
```

### **Estructura de Carpetas**

```
data/parquet/
‚îú‚îÄ‚îÄ falabella/
‚îÇ   ‚îú‚îÄ‚îÄ 2025-09-03/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ smartphones_20250903_143022.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ laptops_20250903_144511.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ televisores_20250903_151234.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata_20250903.json
‚îÇ   ‚îú‚îÄ‚îÄ 2025-09-04/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ smartphones_20250904_090015.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata_20250904.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ ripley/
‚îÇ   ‚îú‚îÄ‚îÄ 2025-09-03/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ smartphones_20250903_145530.parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gaming_20250903_152200.parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata_20250903.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ paris/
‚îî‚îÄ‚îÄ mercadolibre/
```

## üöÄ Implementaci√≥n

### **1. Core System (`core/parquet_backup_system.py`)**

```python
from core.parquet_backup_system import save_scraper_backup, get_backup_stats

# Guardar respaldo desde scraper
result = save_scraper_backup(
    retailer="falabella",
    category="smartphones", 
    products=extracted_products,
    metadata={
        "session_id": "scraping_session_001",
        "source_urls": ["https://falabella.com/smartphones"],
        "execution_time": 45.2,
        "success_rate": 0.98
    }
)
```

### **2. Integraci√≥n Autom√°tica en Base Scraper**

El sistema se integra autom√°ticamente en `portable_orchestrator_v5/core/base_scraper.py`:

```python
# 7. Guardar respaldo en Parquet (datos crudos)
if PARQUET_BACKUP_AVAILABLE and products:
    backup_result = save_scraper_backup(
        retailer=self.retailer,
        category=category,
        products=products,
        metadata=backup_metadata
    )
```

### **3. Caracter√≠sticas T√©cnicas**

#### **Formato de Datos**
- **Formato**: Apache Parquet con compresi√≥n Snappy
- **Optimizaci√≥n**: Tipos de datos optimizados para analytics
- **Compatibilidad**: Pandas, Apache Spark, Dask, BI tools

#### **Campos Autom√°ticos**
- `backup_timestamp`: Timestamp del respaldo
- `backup_id`: ID √∫nico del respaldo (8 chars)
- Todos los campos originales del scraper preservados

#### **Metadata JSON**
```json
{
  "date": "2025-09-03",
  "retailer": "falabella", 
  "backups": [
    {
      "retailer": "falabella",
      "category": "smartphones",
      "timestamp": "2025-09-03T14:30:22",
      "products_count": 156,
      "file_size_mb": 2.34,
      "file_path": "data/parquet/falabella/2025-09-03/smartphones_20250903_143022.parquet",
      "scraping_session_id": "session_001",
      "execution_time_seconds": 45.2,
      "success_rate": 0.98,
      "errors": [],
      "warnings": ["Algunos precios desactualizados"]
    }
  ]
}
```

## üõ†Ô∏è Utilidades de Gesti√≥n

### **Script de Gesti√≥n (`scripts/maintenance/parquet_manager.py`)**

#### **Estad√≠sticas de Respaldos**
```bash
python scripts/maintenance/parquet_manager.py stats
```
Muestra:
- Total de retailers, archivos y tama√±o
- Detalles por retailer
- Respaldos m√°s antiguos/recientes

#### **Listar Respaldos Recientes**
```bash
# Todos los retailers (7 d√≠as)
python scripts/maintenance/parquet_manager.py list

# Espec√≠fico por retailer (15 d√≠as)
python scripts/maintenance/parquet_manager.py list --retailer falabella --days 15
```

#### **Conversi√≥n a Otros Formatos**
```bash
# Convertir a CSV
python scripts/maintenance/parquet_manager.py to-csv data/parquet/falabella/2025-09-03/smartphones_20250903_143022.parquet

# Convertir a Excel
python scripts/maintenance/parquet_manager.py to-excel data/parquet/falabella/2025-09-03/smartphones_20250903_143022.parquet --output smartphones_analysis.xlsx
```

#### **An√°lisis de Archivos**
```bash
python scripts/maintenance/parquet_manager.py analyze data/parquet/falabella/2025-09-03/smartphones_20250903_143022.parquet
```
Proporciona:
- Dimensiones y tama√±o en memoria
- Informaci√≥n de columnas (tipos, nulos, √∫nicos)
- Top marcas, rangos de precios, etc.

#### **Limpieza Autom√°tica**
```bash
# Limpiar respaldos > 30 d√≠as
python scripts/maintenance/parquet_manager.py cleanup --days 30
```

#### **Informaci√≥n Detallada**
```bash
# Info de retailer para hoy
python scripts/maintenance/parquet_manager.py info falabella

# Info para fecha espec√≠fica
python scripts/maintenance/parquet_manager.py info ripley --date 2025-09-03
```

## üìä Casos de Uso

### **1. An√°lisis Hist√≥rico de Precios**
```python
import pandas as pd
import glob

# Leer todos los smartphones de falabella del √∫ltimo mes
files = glob.glob("data/parquet/falabella/*/smartphones_*.parquet")
dfs = [pd.read_parquet(f) for f in files]
smartphones_history = pd.concat(dfs)

# An√°lisis de evoluci√≥n de precios
price_evolution = smartphones_history.groupby(['nombre', 'backup_timestamp'])['precio_normal'].mean()
```

### **2. Comparaci√≥n Cross-Retailer**
```python
# Cargar datos de m√∫ltiples retailers
falabella_data = pd.read_parquet("data/parquet/falabella/2025-09-03/smartphones_20250903_143022.parquet")
ripley_data = pd.read_parquet("data/parquet/ripley/2025-09-03/smartphones_20250903_145530.parquet")

# Comparar precios por marca
comparison = pd.merge(
    falabella_data[['nombre', 'marca', 'precio_normal']],
    ripley_data[['nombre', 'marca', 'precio_normal']], 
    on=['nombre', 'marca'], 
    suffixes=['_falabella', '_ripley']
)
```

### **3. Recuperaci√≥n de Datos**
```python
from core.parquet_backup_system import ParquetBackupSystem

system = ParquetBackupSystem()

# Listar respaldos disponibles
backups = system.list_backups(retailer="falabella", days_back=30)

# Leer respaldo espec√≠fico
df = system.read_backup(backups[0]['path'])
```

### **4. Integraci√≥n con BI Tools**
- **Power BI**: Conectar directamente a archivos Parquet
- **Tableau**: Usar connector de Parquet
- **Apache Spark**: Lectura nativa de Parquet para big data analytics

## ‚öôÔ∏è Configuraci√≥n

### **Variables de Configuraci√≥n**
```python
# En core/parquet_backup_system.py
class ParquetBackupSystem:
    def __init__(self):
        self.compression = 'snappy'        # Compresi√≥n utilizada
        self.max_file_size_mb = 100        # Tama√±o m√°ximo por archivo
        self.max_age_days = 30             # D√≠as de retenci√≥n
```

### **Variables de Entorno**
```bash
# En .env (opcional)
PARQUET_BACKUP_PATH=data/parquet          # Path base para respaldos
PARQUET_COMPRESSION=snappy                # Tipo de compresi√≥n
PARQUET_MAX_AGE_DAYS=30                   # D√≠as de retenci√≥n
```

## üöÄ Benefits del Sistema

### **Ventajas del Formato Parquet**
- **Compresi√≥n**: 70-90% menor que CSV
- **Velocidad**: 10-100x m√°s r√°pido que CSV para analytics  
- **Tipado**: Preserva tipos de datos originales
- **Compatibilidad**: Est√°ndar en el ecosistema big data

### **Organizaci√≥n Inteligente**
- **Por Retailer**: Facilita an√°lisis por fuente
- **Por Fecha**: Permite an√°lisis temporal
- **Por Categor√≠a**: Segmentaci√≥n por tipo de producto
- **Metadata**: Contexto completo de cada respaldo

### **Recuperaci√≥n de Desastres**
- **Respaldo Completo**: Datos crudos preservados
- **Independiente**: No depende de PostgreSQL
- **Versionado**: M√∫ltiples snapshots en el tiempo
- **Portable**: Archivos aut√≥nomos y transferibles

## üîß Troubleshooting

### **Error: "pyarrow not installed"**
```bash
pip install pyarrow
```

### **Error: "Permission denied"**
- Verificar permisos de escritura en directorio `data/parquet/`
- En Windows, ejecutar como administrador si es necesario

### **Archivos muy grandes**
- El sistema autom√°ticamente divide archivos > 100MB
- Configurar `max_file_size_mb` seg√∫n necesidades

### **Memoria insuficiente**
- Procesar archivos Parquet en chunks:
```python
import pandas as pd
for chunk in pd.read_parquet('large_file.parquet', chunksize=1000):
    process(chunk)
```

## üìà M√©tricas y Monitoreo

### **M√©tricas Autom√°ticas**
- Productos respaldados por d√≠a
- Tama√±o de respaldos por retailer
- Tiempo de ejecuci√≥n por categor√≠a
- Tasa de √©xito por scraper

### **Alertas Recomendadas**
- Respaldos no creados en 24h
- Tama√±o de respaldos excesivamente grande/peque√±o
- Errores recurrentes en respaldos
- Espacio en disco < 1GB

---

**üéâ Sistema de Respaldo Parquet completamente implementado y operativo**

Para m√°s detalles t√©cnicos, revisar:
- `core/parquet_backup_system.py` - Sistema principal
- `tests/integration/test_parquet_backup.py` - Tests completos
- `scripts/maintenance/parquet_manager.py` - Utilidades de gesti√≥n